{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vA1KLcsK7094"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBoxRG6a7rF_",
        "outputId": "1a890af0-70ca-44c9-b6f4-af6b52600d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: timeout_decorator in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/mPDE-Net/')\n",
        "sys.path.append('/content/drive/MyDrive/mPDE-Net/aTEAM/')\n",
        "!pip install timeout_decorator\n",
        "!pip install -U PyYAML"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#mPDE-Net"
      ],
      "metadata": {
        "id": "efdBtEhp79_7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmBTpBEXwqpe",
        "outputId": "946b0389-16a1-485d-cf00-f3bde33cb679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-fd716b693a75>:6: DeprecationWarning: Please use `fmin_l_bfgs_b` from the `scipy.optimize` namespace, the `scipy.optimize.lbfgsb` namespace is deprecated.\n",
            "  from scipy.optimize.lbfgsb import fmin_l_bfgs_b as lbfgsb\n",
            "<ipython-input-2-fd716b693a75>:7: DeprecationWarning: Please use `fmin_slsqp` from the `scipy.optimize` namespace, the `scipy.optimize.slsqp` namespace is deprecated.\n",
            "  from scipy.optimize.slsqp import fmin_slsqp as slsqp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brusselator\n",
            "initgenb\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0423,  0.8910,  0.7786, 17.4955,  6.6314, 15.1613,  0.0508,  1.0199,\n",
            "         1.0419, 19.8258,  9.2510, 20.4589], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 31.212386\n",
            "         Iterations: 95\n",
            "         Function evaluations: 165\n",
            "         Gradient evaluations: 153\n",
            "convolution moment and kernels\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.    1.    0.   -0.33 -0.25]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.11e-16  2.22e-16 -1.50e+00  2.00e+00 -5.00e-01]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 1.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [-0.33  0.    0.    0.    0.  ]\n",
            " [-0.25  0.    0.    0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.11e-16  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  2.22e-16  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00 -1.50e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  2.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00 -5.00e-01  0.00e+00  0.00e+00]]\n",
            "[[0.   0.   1.   0.   0.08]\n",
            " [0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-3.19e-16  1.00e+00 -2.00e+00  1.00e+00 -2.13e-16]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.  ]\n",
            " [1.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.  ]\n",
            " [0.08 0.   0.   0.   0.  ]]\n",
            "[[ 0.00e+00  0.00e+00 -3.19e-16  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00 -2.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00 -2.13e-16  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-2.05  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.3   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.44 0.27]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  1.  0. ]]\n",
            "SymNet parameters\n",
            "[0.5 0.5]\n",
            "SymNet parameters\n",
            "[[0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.07 0.03]\n",
            "SymNet parameters\n",
            "[[2.63e-03 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 3.01e-03 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.16e-05 1.07e-03]\n",
            " [8.52e-03 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 2.07e-03 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.59e-06 8.86e-03]]\n",
            "SymNet parameters\n",
            "[0.   0.07]\n",
            "SymNet parameters\n",
            "[[0.43 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.06 0.\n",
            "  0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.54 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.96 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.99  0.    0.    0.44  0.    0.44 -0.44  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.01  0.    0.3   0.58]]\n",
            "SymNet parameters\n",
            "[0.94]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.42  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.46  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.13 0.44]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  1.  0. ]]\n",
            "SymNet parameters\n",
            "[0.5 0.5]\n",
            "SymNet parameters\n",
            "[[0.01 0.   0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.01 0.   0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.05 0.03]\n",
            "SymNet parameters\n",
            "[[ 0.09  0.    0.    0.    0.    0.    0.08  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.   -0.    0.06]\n",
            " [ 0.08  0.    0.    0.    0.    0.    0.1   0.    0.    0.    0.    0.    0.    0.\n",
            "   0.   -0.    0.03]]\n",
            "SymNet parameters\n",
            "[0.06 0.06]\n",
            "SymNet parameters\n",
            "[[0.43 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.\n",
            "  0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    2.22  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.51  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.44  0.    0.    0.    0.    0.    0.25  0.    0.    0.51  0.    0.51  0.    0.\n",
            "   0.    0.    0.01  0.    0.18 -0.48]]\n",
            "SymNet parameters\n",
            "[-1.64]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0423,  0.8910,  0.7786, 17.4955,  6.6314, 15.1613,  0.0508,  1.0199,\n",
            "         1.0419, 19.8258,  9.2510, 20.4589], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 25.833777\n",
            "         Iterations: 152\n",
            "         Function evaluations: 221\n",
            "         Gradient evaluations: 209\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    1.89 -0.17  1.85]\n",
            " [ 0.    0.01 -0.59 -0.26 -0.25]\n",
            " [ 1.03 -0.88  1.66 -1.83  1.04]\n",
            " [-0.1   0.53 -1.2   0.5  -0.48]\n",
            " [ 0.85 -0.41  0.55 -0.73  0.24]]\n",
            "[[ 0.66 -0.65  0.64  0.25 -0.08]\n",
            " [-0.31 -1.04  0.54 -2.    0.67]\n",
            " [ 0.57 -1.19  5.12 -1.62  0.65]\n",
            " [ 0.76 -2.    0.41 -1.66  0.56]\n",
            " [ 0.09 -0.18  0.67  0.32 -0.2 ]]\n",
            "[[ 0.    1.    0.   -0.21 -0.13]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.36 -0.79  1.4  -0.32]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 1.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [-0.21  0.    0.    0.    0.  ]\n",
            " [-0.13  0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.06  0.    0.  ]\n",
            " [ 0.    0.   -0.36  0.    0.  ]\n",
            " [ 0.    0.   -0.79  0.    0.  ]\n",
            " [ 0.    0.    1.4   0.    0.  ]\n",
            " [ 0.    0.   -0.32  0.    0.  ]]\n",
            "[[ 0.    0.    1.    0.   -0.61]\n",
            " [ 0.    0.    0.   -0.04  0.05]\n",
            " [ 0.    0.    2.38 -0.01  1.55]\n",
            " [ 0.    0.08  0.02  0.05  0.03]\n",
            " [-0.72 -0.02  1.54 -0.01  0.79]]\n",
            "[[  0.55  -0.8   -0.19  -0.8    0.52]\n",
            " [ -0.87   0.35   3.83   0.33  -0.78]\n",
            " [ -0.12   4.85 -13.68   4.8   -0.16]\n",
            " [ -0.81   0.27   3.91   0.34  -0.84]\n",
            " [  0.55  -0.88  -0.07  -0.88   0.56]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.    0.    0.    0.   -0.7 ]\n",
            " [ 0.    0.    0.   -0.04  0.05]\n",
            " [ 1.    0.    2.38 -0.01  1.55]\n",
            " [ 0.    0.08  0.02  0.05  0.03]\n",
            " [-0.63 -0.02  1.54 -0.01  0.79]]\n",
            "[[  0.55  -0.8   -0.19  -0.8    0.52]\n",
            " [ -0.87   0.35   4.83   0.33  -0.78]\n",
            " [ -0.12   3.85 -13.68   3.8   -0.16]\n",
            " [ -0.81   0.27   4.91   0.34  -0.84]\n",
            " [  0.55  -0.88  -0.07  -0.88   0.56]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[1.84 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [1.79 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[3.28 1.17]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.32 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.32 0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.32 0.32]\n",
            "SymNet parameters\n",
            "[[-0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.39e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.08e-04  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.54e-06\n",
            "  -5.95e-05]\n",
            " [-4.14e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.91e-04  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.27e-07\n",
            "  -6.89e-04]]\n",
            "SymNet parameters\n",
            "[-0.    0.01]\n",
            "SymNet parameters\n",
            "[[ 0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.   -0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.79 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.06 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 2.31e+00  0.00e+00  0.00e+00  1.85e-01  0.00e+00  1.85e-01 -1.81e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -1.37e-03  1.18e-03  1.23e-01  9.78e-01]]\n",
            "SymNet parameters\n",
            "[-0.77]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.53  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.43  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.05 0.79]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.32 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.32 0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.32 0.32]\n",
            "SymNet parameters\n",
            "[[-1.16e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.01e-04  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 2.36e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.19e-05  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0.01 0.  ]\n",
            "SymNet parameters\n",
            "[[-4.75e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.28e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.11e-05\n",
            "   6.41e-03]\n",
            " [ 5.10e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.73e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.62e-05\n",
            "   2.56e-03]]\n",
            "SymNet parameters\n",
            "[0.01 0.01]\n",
            "SymNet parameters\n",
            "[[2.46e-01 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 7.93e-05 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    2.19  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.65  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 1.09  0.    0.    0.    0.    0.   -0.26  0.    0.    0.21  0.    0.21  0.    0.\n",
            "   0.    0.    0.    0.    0.   -0.62]]\n",
            "SymNet parameters\n",
            "[0.41]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([3.0918e-02, 7.5567e-01, 6.5965e-01, 1.0119e+02, 6.6314e+00, 9.7268e+01,\n",
            "        3.6768e-02, 8.6589e-01, 8.8337e-01, 1.2037e+02, 9.2510e+00, 1.2159e+02],\n",
            "       dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 51.688585\n",
            "         Iterations: 88\n",
            "         Function evaluations: 160\n",
            "         Gradient evaluations: 148\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.38 -0.05  0.3 ]\n",
            " [ 0.    0.25 -0.01  0.17  0.11]\n",
            " [ 0.04 -0.74 -1.09 -1.07 -1.05]\n",
            " [ 0.1   0.29 -0.1   0.23 -0.05]\n",
            " [ 0.1  -0.6  -0.81 -0.61 -0.53]]\n",
            "[[-0.1   0.59 -0.77  0.94 -0.61]\n",
            " [ 0.05 -0.12 -0.74 -0.33  0.91]\n",
            " [ 0.22 -1.03  4.1  -1.29 -0.51]\n",
            " [ 0.37 -0.93  0.07 -1.    1.04]\n",
            " [-0.24  0.76 -0.82  1.04 -0.59]]\n",
            "[[ 0.    1.    0.   -0.16 -0.08]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.09 -0.51 -0.47  1.14 -0.24]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 1.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [-0.16  0.    0.    0.    0.  ]\n",
            " [-0.08  0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.09  0.    0.  ]\n",
            " [ 0.    0.   -0.51  0.    0.  ]\n",
            " [ 0.    0.   -0.47  0.    0.  ]\n",
            " [ 0.    0.    1.14  0.    0.  ]\n",
            " [ 0.    0.   -0.24  0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.60e-01]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  2.11e-03  3.63e-02]\n",
            " [ 0.00e+00  0.00e+00  1.61e+00 -1.33e-03  1.08e+00]\n",
            " [ 0.00e+00  1.23e-02 -1.64e-02  5.62e-03  1.23e-02]\n",
            " [-2.58e-01 -3.75e-03  1.05e+00 -9.09e-04  5.14e-01]]\n",
            "[[ 0.35 -0.45 -0.04 -0.46  0.34]\n",
            " [-0.46 -0.25  2.42 -0.23 -0.46]\n",
            " [-0.05  3.47 -8.37  3.44 -0.04]\n",
            " [-0.44 -0.29  2.49 -0.29 -0.44]\n",
            " [ 0.35 -0.5   0.04 -0.5   0.35]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.44e-01]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  2.11e-03  3.63e-02]\n",
            " [ 1.00e+00  0.00e+00  1.61e+00 -1.33e-03  1.08e+00]\n",
            " [ 0.00e+00  1.23e-02 -1.64e-02  5.62e-03  1.23e-02]\n",
            " [-1.75e-01 -3.75e-03  1.05e+00 -9.09e-04  5.14e-01]]\n",
            "[[ 0.35 -0.45 -0.04 -0.46  0.34]\n",
            " [-0.46 -0.25  3.42 -0.23 -0.46]\n",
            " [-0.05  2.47 -8.37  2.44 -0.04]\n",
            " [-0.44 -0.29  3.49 -0.29 -0.44]\n",
            " [ 0.35 -0.5   0.04 -0.5   0.35]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.4  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
            " [ 0.5  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0. ]]\n",
            "SymNet parameters\n",
            "[0.5 0.4]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.24 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.24 0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.24 0.24]\n",
            "SymNet parameters\n",
            "[[ 1.01e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.19e-06  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-5.07e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.08e-06  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[ 3.50e-04 -1.32e-05]\n",
            "SymNet parameters\n",
            "[[ 2.46e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.00e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.54e-08\n",
            "   1.23e-06]\n",
            " [ 8.62e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.07e-06  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.53e-09\n",
            "   1.43e-05]]\n",
            "SymNet parameters\n",
            "[ 1.87e-06 -1.27e-03]\n",
            "SymNet parameters\n",
            "[[0.17 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.14 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.29 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.07e-01  0.00e+00  0.00e+00  2.61e-01  0.00e+00  2.61e-01 -1.21e-01  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   3.65e-05  1.18e-03  4.55e-02  8.50e-01]]\n",
            "SymNet parameters\n",
            "[0.7]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.27  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.06  0.46]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.24 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.24 0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.24 0.24]\n",
            "SymNet parameters\n",
            "[[ 2.63e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.35e-06  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-1.70e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.47e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-0. -0.]\n",
            "SymNet parameters\n",
            "[[ 1.13e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.37e-04  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.55e-07\n",
            "  -5.30e-05]\n",
            " [-1.47e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -7.92e-05  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.95e-07\n",
            "  -1.54e-04]]\n",
            "SymNet parameters\n",
            "[-5.38e-05 -1.29e-03]\n",
            "SymNet parameters\n",
            "[[ 1.67e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.15e-07\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    2.08  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.5   0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 4.23e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.92e-01  0.00e+00\n",
            "   0.00e+00  3.15e-01  0.00e+00  3.15e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -6.76e-05  3.47e-03 -1.74e-04 -4.77e-01]]\n",
            "SymNet parameters\n",
            "[0.59]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([4.0714e-02, 7.0472e-01, 6.1527e-01, 4.3747e+01, 6.6314e+00, 4.1061e+01,\n",
            "        4.9254e-02, 8.0801e-01, 8.2373e-01, 5.1301e+01, 9.2510e+00, 5.2128e+01],\n",
            "       dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 76.791375\n",
            "         Iterations: 45\n",
            "         Function evaluations: 100\n",
            "         Gradient evaluations: 89\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.2  -0.08  0.14]\n",
            " [ 0.    0.08  0.03  0.03  0.06]\n",
            " [ 0.08 -0.56 -0.93 -0.96 -1.05]\n",
            " [ 0.05  0.26 -0.1   0.23 -0.07]\n",
            " [ 0.14 -0.45 -0.59 -0.56 -0.46]]\n",
            "[[-0.04  0.47 -0.73  0.94 -0.54]\n",
            " [-0.24  0.36 -0.95 -0.26  0.71]\n",
            " [ 0.5  -1.55  4.23 -1.27 -0.31]\n",
            " [ 0.15 -0.37 -0.31 -0.7   0.74]\n",
            " [-0.21  0.71 -0.89  1.07 -0.52]]\n",
            "[[ 0.    1.    0.   -0.15 -0.07]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.09 -0.55 -0.41  1.09 -0.23]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 1.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [-0.15  0.    0.    0.    0.  ]\n",
            " [-0.07  0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.09  0.    0.  ]\n",
            " [ 0.    0.   -0.55  0.    0.  ]\n",
            " [ 0.    0.   -0.41  0.    0.  ]\n",
            " [ 0.    0.    1.09  0.    0.  ]\n",
            " [ 0.    0.   -0.23  0.    0.  ]]\n",
            "[[ 0.    0.    1.    0.   -0.06]\n",
            " [ 0.    0.    0.    0.01  0.02]\n",
            " [ 0.    0.    1.19 -0.01  0.81]\n",
            " [ 0.    0.01 -0.02  0.01  0.  ]\n",
            " [-0.15  0.    0.77 -0.    0.36]]\n",
            "[[ 0.24 -0.28 -0.08 -0.27  0.24]\n",
            " [-0.26 -0.47  2.08 -0.48 -0.26]\n",
            " [-0.12  3.13 -6.94  3.15 -0.12]\n",
            " [-0.24 -0.53  2.15 -0.55 -0.24]\n",
            " [ 0.24 -0.29 -0.05 -0.29  0.24]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.    0.    0.    0.   -0.14]\n",
            " [ 0.    0.    0.    0.01  0.02]\n",
            " [ 1.    0.    1.19 -0.01  0.81]\n",
            " [ 0.    0.01 -0.02  0.01  0.  ]\n",
            " [-0.07  0.    0.77 -0.    0.36]]\n",
            "[[ 0.24 -0.28 -0.08 -0.27  0.24]\n",
            " [-0.26 -0.47  3.08 -0.48 -0.26]\n",
            " [-0.12  2.13 -6.94  2.15 -0.12]\n",
            " [-0.24 -0.53  3.15 -0.55 -0.24]\n",
            " [ 0.24 -0.29 -0.05 -0.29  0.24]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.44  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.31  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.03 0.32]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.23 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.23 0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.22 0.23]\n",
            "SymNet parameters\n",
            "[[-7.33e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.75e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 3.66e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.95e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-2.53e-05  9.57e-07]\n",
            "SymNet parameters\n",
            "[[-1.68e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.06e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.22e-10\n",
            "  -8.91e-08]\n",
            " [-6.23e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.94e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.57e-10\n",
            "  -1.03e-06]]\n",
            "SymNet parameters\n",
            "[-1.41e-07  9.59e-05]\n",
            "SymNet parameters\n",
            "[[ 1.57e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.45e-05\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.13 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.28 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-7.93e-01  0.00e+00  0.00e+00  2.79e-01  0.00e+00  2.79e-01 -8.17e-04  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -2.64e-06  1.18e-03  2.91e-02  8.44e-01]]\n",
            "SymNet parameters\n",
            "[0.93]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.27  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.38]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.23 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.23 0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.22 0.23]\n",
            "SymNet parameters\n",
            "[[-1.90e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.41e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.23e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.99e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[1.07e-04 1.23e-05]\n",
            "SymNet parameters\n",
            "[[-1.28e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.00e-05  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.77e-08\n",
            "   3.83e-06]\n",
            " [ 1.18e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.64e-06  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.40e-08\n",
            "   1.11e-05]]\n",
            "SymNet parameters\n",
            "[3.89e-06 9.87e-05]\n",
            "SymNet parameters\n",
            "[[1.50e-01 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 8.82e-08 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    2.07  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.46  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 3.31e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.26e-01  0.00e+00\n",
            "   0.00e+00  3.51e-01  0.00e+00  3.51e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   4.88e-06  3.47e-03  1.26e-05 -4.35e-01]]\n",
            "SymNet parameters\n",
            "[0.52]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0426,  0.6949,  0.6067, 34.0184,  6.6314, 31.5099,  0.0514,  0.7968,\n",
            "         0.8122, 39.6882,  9.2510, 40.3752], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 101.083367\n",
            "         Iterations: 94\n",
            "         Function evaluations: 163\n",
            "         Gradient evaluations: 151\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.09 -0.03  0.05]\n",
            " [ 0.    0.07 -0.11  0.    0.  ]\n",
            " [ 0.04 -0.28 -0.9  -0.53 -0.95]\n",
            " [ 0.02  0.04 -0.21 -0.02 -0.07]\n",
            " [ 0.09 -0.21 -0.54 -0.31 -0.39]]\n",
            "[[-0.13  0.5  -0.68  0.75 -0.36]\n",
            " [-0.06  0.4  -0.93 -0.05  0.38]\n",
            " [ 0.39 -1.71  4.1  -1.27 -0.09]\n",
            " [ 0.04  0.23 -0.82 -0.29  0.52]\n",
            " [-0.18  0.48 -0.59  0.81 -0.43]]\n",
            "[[ 0.    1.    0.   -0.    0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.15 -0.93  0.39  0.41 -0.02]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 1.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [-0.    0.    0.    0.    0.  ]\n",
            " [ 0.06  0.    0.    0.    0.  ]]\n",
            "[[ 0.    0.    0.15  0.    0.  ]\n",
            " [ 0.    0.   -0.93  0.    0.  ]\n",
            " [ 0.    0.    0.39  0.    0.  ]\n",
            " [ 0.    0.    0.41  0.    0.  ]\n",
            " [ 0.    0.   -0.02  0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00 -1.55e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  5.16e-03  2.35e-02]\n",
            " [ 0.00e+00  0.00e+00  9.18e-01 -1.40e-03  6.12e-01]\n",
            " [ 0.00e+00  1.15e-03 -1.59e-02 -7.33e-04  5.56e-03]\n",
            " [-1.06e-01  6.79e-03  5.93e-01  3.97e-03  2.58e-01]]\n",
            "[[ 0.16 -0.13 -0.18 -0.13  0.16]\n",
            " [-0.12 -0.64  1.96 -0.64 -0.14]\n",
            " [-0.19  3.   -6.26  3.   -0.17]\n",
            " [-0.11 -0.67  2.01 -0.68 -0.12]\n",
            " [ 0.16 -0.16 -0.13 -0.15  0.17]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.86e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  5.16e-03  2.35e-02]\n",
            " [ 1.00e+00  0.00e+00  9.18e-01 -1.40e-03  6.12e-01]\n",
            " [ 0.00e+00  1.15e-03 -1.59e-02 -7.33e-04  5.56e-03]\n",
            " [-2.24e-02  6.79e-03  5.93e-01  3.97e-03  2.58e-01]]\n",
            "[[ 0.16 -0.13 -0.18 -0.13  0.16]\n",
            " [-0.12 -0.64  2.96 -0.64 -0.14]\n",
            " [-0.19  2.   -6.26  1.99 -0.17]\n",
            " [-0.11 -0.67  3.01 -0.68 -0.12]\n",
            " [ 0.16 -0.16 -0.13 -0.15  0.17]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.27  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.28]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 2.87e-04 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.20e-04 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.22e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.65e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.61e-08  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.30e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-1.11e-06  4.20e-08]\n",
            "SymNet parameters\n",
            "[[-6.94e-09  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.95e-09  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.08e-10\n",
            "  -3.91e-09]\n",
            " [-2.74e-08  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.29e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.14e-11\n",
            "  -4.53e-08]]\n",
            "SymNet parameters\n",
            "[-4.78e-09  4.21e-06]\n",
            "SymNet parameters\n",
            "[[-5.88e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.64e-06\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.13 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.2  0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-9.16e-01  0.00e+00  0.00e+00  2.85e-01  0.00e+00  2.85e-01  6.70e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -1.16e-07  1.18e-03  1.71e-02  8.24e-01]]\n",
            "SymNet parameters\n",
            "[0.96]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.58  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.26  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.35]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.89e-04 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.71e-04 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-8.36e-08  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.06e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 5.39e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.32e-09  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[4.7e-06 5.4e-07]\n",
            "SymNet parameters\n",
            "[[-1.33e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.64e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.61e-09\n",
            "   1.68e-07]\n",
            " [ 5.19e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.38e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.92e-09\n",
            "   4.88e-07]]\n",
            "SymNet parameters\n",
            "[1.62e-07 4.34e-06]\n",
            "SymNet parameters\n",
            "[[-6.48e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.29e-09\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    1.92  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.47  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 2.12e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.06e-01  0.00e+00\n",
            "   0.00e+00  3.66e-01  0.00e+00  3.66e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   2.14e-07  3.47e-03  5.53e-07 -4.50e-01]]\n",
            "SymNet parameters\n",
            "[0.46]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0432,  0.5805,  0.5087, 30.5279,  6.6314, 28.0755,  0.0522,  0.6674,\n",
            "         0.6786, 35.5399,  9.2510, 36.1951], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 124.473080\n",
            "         Iterations: 48\n",
            "         Function evaluations: 97\n",
            "         Gradient evaluations: 85\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.07 -0.02  0.02]\n",
            " [ 0.    0.01 -0.16 -0.03 -0.05]\n",
            " [ 0.07 -0.22 -0.77 -0.54 -0.91]\n",
            " [ 0.03 -0.1  -0.22 -0.15 -0.07]\n",
            " [ 0.11 -0.11 -0.39 -0.28 -0.34]]\n",
            "[[-0.13  0.48 -0.73  0.76 -0.29]\n",
            " [-0.08  0.44 -0.78 -0.11  0.21]\n",
            " [ 0.49 -1.9   4.03 -1.26  0.12]\n",
            " [-0.14  0.57 -0.99 -0.19  0.37]\n",
            " [-0.11  0.38 -0.56  0.81 -0.4 ]]\n",
            "[[ 0.00e+00  1.00e+00  0.00e+00 -1.92e-04  5.44e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.14 -0.88  0.33  0.45 -0.03]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-1.92e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 5.44e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.14  0.    0.  ]\n",
            " [ 0.    0.   -0.88  0.    0.  ]\n",
            " [ 0.    0.    0.33  0.    0.  ]\n",
            " [ 0.    0.    0.45  0.    0.  ]\n",
            " [ 0.    0.   -0.03  0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  1.95e-03]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  4.28e-03  1.87e-02]\n",
            " [ 0.00e+00  0.00e+00  7.47e-01 -7.37e-03  4.88e-01]\n",
            " [ 0.00e+00 -4.62e-03 -1.30e-02 -7.92e-03  3.09e-03]\n",
            " [-7.17e-02  5.64e-03  4.71e-01  3.07e-04  1.89e-01]]\n",
            "[[ 0.11 -0.04 -0.22 -0.04  0.12]\n",
            " [-0.03 -0.74  1.84 -0.73 -0.05]\n",
            " [-0.25  2.93 -5.81  2.94 -0.24]\n",
            " [-0.03 -0.76  1.89 -0.79 -0.02]\n",
            " [ 0.12 -0.06 -0.19 -0.05  0.11]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.10e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  4.28e-03  1.87e-02]\n",
            " [ 1.00e+00  0.00e+00  7.47e-01 -7.37e-03  4.88e-01]\n",
            " [ 0.00e+00 -4.62e-03 -1.30e-02 -7.92e-03  3.09e-03]\n",
            " [-1.93e-03  5.64e-03  4.71e-01  3.07e-04  1.89e-01]]\n",
            "[[ 0.11 -0.04 -0.23 -0.04  0.12]\n",
            " [-0.03 -0.74  2.89 -0.73 -0.05]\n",
            " [-0.23  1.85 -5.77  1.86 -0.22]\n",
            " [-0.03 -0.76  2.94 -0.79 -0.02]\n",
            " [ 0.12 -0.06 -0.2  -0.05  0.11]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.26  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.    0.27]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.79e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.42e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-5.55e-08 -3.25e-08]\n",
            "SymNet parameters\n",
            "[[ 6.49e-11  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.32e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-3.24e-12  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.62e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[ 2.24e-10 -8.47e-12]\n",
            "SymNet parameters\n",
            "[[ 3.03e-11  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.09e-11  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.12e-14\n",
            "   7.89e-13]\n",
            " [ 6.04e-12  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.78e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.30e-15\n",
            "   9.13e-12]]\n",
            "SymNet parameters\n",
            "[-1.65e-13 -8.49e-10]\n",
            "SymNet parameters\n",
            "[[-4.30e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.08e-10\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.13 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.17 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-9.45e-01  0.00e+00  0.00e+00  2.91e-01  0.00e+00  2.91e-01  2.58e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   2.33e-11  1.18e-03  1.34e-03  7.86e-01]]\n",
            "SymNet parameters\n",
            "[0.98]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.55  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.26  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.31]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.80e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.44e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-5.98e-08 -3.62e-08]\n",
            "SymNet parameters\n",
            "[[ 1.68e-11  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.13e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-1.09e-10  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.20e-13  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-9.47e-10 -1.09e-10]\n",
            "SymNet parameters\n",
            "[[-2.08e-09  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.91e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.67e-13\n",
            "  -3.39e-11]\n",
            " [-9.48e-10  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.46e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.98e-13\n",
            "  -9.83e-11]]\n",
            "SymNet parameters\n",
            "[ 3.68e-10 -9.50e-10]\n",
            "SymNet parameters\n",
            "[[-4.91e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -7.06e-13\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    1.88  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.45  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 1.25e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.07e-01  0.00e+00\n",
            "   0.00e+00  3.76e-01  0.00e+00  3.76e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -4.32e-11  3.47e-03 -1.11e-10 -4.47e-01]]\n",
            "SymNet parameters\n",
            "[0.45]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0431,  0.5790,  0.5074, 28.6357,  6.6314, 25.9840,  0.0519,  0.6657,\n",
            "         0.6769, 33.2419,  9.2510, 33.6269], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 147.484328\n",
            "         Iterations: 31\n",
            "         Function evaluations: 109\n",
            "         Gradient evaluations: 97\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.06 -0.02  0.03]\n",
            " [ 0.    0.03 -0.12 -0.03 -0.03]\n",
            " [ 0.02 -0.23 -0.8  -0.5  -0.85]\n",
            " [ 0.04 -0.08 -0.17 -0.17 -0.08]\n",
            " [ 0.07 -0.14 -0.4  -0.28 -0.31]]\n",
            "[[-0.11  0.36 -0.52  0.58 -0.25]\n",
            " [-0.13  0.61 -1.03  0.17  0.16]\n",
            " [ 0.54 -1.97  4.03 -1.35  0.11]\n",
            " [-0.17  0.58 -0.88 -0.22  0.4 ]\n",
            " [-0.09  0.34 -0.55  0.79 -0.39]]\n",
            "[[ 0.00e+00  1.00e+00  0.00e+00 -1.83e-04  5.35e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.14 -0.88  0.32  0.45 -0.03]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-1.83e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 5.35e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.14  0.    0.  ]\n",
            " [ 0.    0.   -0.88  0.    0.  ]\n",
            " [ 0.    0.    0.32  0.    0.  ]\n",
            " [ 0.    0.    0.45  0.    0.  ]\n",
            " [ 0.    0.   -0.03  0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  1.36e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -1.88e-04  1.11e-02]\n",
            " [ 0.00e+00  0.00e+00  6.17e-01 -4.30e-03  3.95e-01]\n",
            " [ 0.00e+00  4.84e-03 -8.65e-03 -3.85e-04 -1.13e-03]\n",
            " [-5.56e-02  6.51e-04  3.83e-01 -1.51e-03  1.40e-01]]\n",
            "[[ 0.08  0.02 -0.25  0.02  0.08]\n",
            " [ 0.02 -0.8   1.78 -0.8   0.02]\n",
            " [-0.28  2.89 -5.55  2.89 -0.28]\n",
            " [ 0.03 -0.84  1.84 -0.85  0.04]\n",
            " [ 0.08  0.01 -0.24  0.02  0.08]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.74e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -1.88e-04  1.11e-02]\n",
            " [ 1.00e+00  0.00e+00  6.17e-01 -4.30e-03  3.95e-01]\n",
            " [ 0.00e+00  4.84e-03 -8.65e-03 -3.85e-04 -1.13e-03]\n",
            " [ 1.20e-02  6.51e-04  3.83e-01 -1.51e-03  1.40e-01]]\n",
            "[[ 0.08  0.02 -0.26  0.02  0.08]\n",
            " [ 0.02 -0.8   2.84 -0.8   0.02]\n",
            " [-0.26  1.8  -5.51  1.8  -0.26]\n",
            " [ 0.03 -0.84  2.9  -0.85  0.04]\n",
            " [ 0.08  0.01 -0.26  0.02  0.08]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.26  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.27]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.72e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -7.19e-08  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-1.65e-07 -9.65e-08]\n",
            "SymNet parameters\n",
            "[[ 1.93e-10  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  9.87e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-9.63e-12  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.77e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[ 6.65e-10 -2.52e-11]\n",
            "SymNet parameters\n",
            "[[ 7.94e-12  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.92e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.50e-14\n",
            "   2.34e-12]\n",
            " [ 1.65e-11  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.77e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.83e-15\n",
            "   2.71e-11]]\n",
            "SymNet parameters\n",
            "[ 2.67e-12 -2.52e-09]\n",
            "SymNet parameters\n",
            "[[-4.17e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.04e-09\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.14 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.17 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-9.49e-01  0.00e+00  0.00e+00  2.92e-01  0.00e+00  2.92e-01  3.44e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   6.94e-11  1.18e-03  2.58e-04  7.88e-01]]\n",
            "SymNet parameters\n",
            "[0.99]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.55  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.02  0.29]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.13e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.02e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-1.78e-07 -1.08e-07]\n",
            "SymNet parameters\n",
            "[[ 5.01e-11  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.35e-12  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-3.23e-10  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.97e-13  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-2.82e-09 -3.24e-10]\n",
            "SymNet parameters\n",
            "[[-1.99e-10  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.42e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.58e-13\n",
            "  -1.01e-10]\n",
            " [-3.10e-09  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.07e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.75e-12\n",
            "  -2.92e-10]]\n",
            "SymNet parameters\n",
            "[-4.27e-11 -2.61e-09]\n",
            "SymNet parameters\n",
            "[[-4.77e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.98e-12\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    1.88  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.44  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 6.52e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.96e-01  0.00e+00\n",
            "   0.00e+00  3.80e-01  0.00e+00  3.80e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -1.29e-10  3.47e-03 -3.31e-10 -4.38e-01]]\n",
            "SymNet parameters\n",
            "[0.44]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0438,  0.5789,  0.5073, 27.6825,  6.6314, 25.0222,  0.0527,  0.6656,\n",
            "         0.6768, 32.1118,  9.2510, 32.4747], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 213.941020\n",
            "         Iterations: 54\n",
            "         Function evaluations: 127\n",
            "         Gradient evaluations: 115\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.01 -0.01  0.01]\n",
            " [ 0.    0.02  0.03 -0.05  0.07]\n",
            " [ 0.02 -0.16 -0.61 -0.33 -0.61]\n",
            " [ 0.03 -0.07  0.06 -0.19  0.11]\n",
            " [ 0.05 -0.11 -0.3  -0.21 -0.2 ]]\n",
            "[[-0.14  0.38 -0.47  0.48 -0.22]\n",
            " [-0.08  0.47 -0.87  0.19  0.13]\n",
            " [ 0.52 -1.88  3.82 -1.33  0.13]\n",
            " [-0.33  1.06 -1.47  0.37  0.16]\n",
            " [ 0.04 -0.07  0.01  0.3  -0.21]]\n",
            "[[ 0.00e+00  1.00e+00  0.00e+00 -6.11e-05  4.43e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.13 -0.84  0.27  0.49 -0.04]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-6.11e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 4.43e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.13  0.    0.  ]\n",
            " [ 0.    0.   -0.84  0.    0.  ]\n",
            " [ 0.    0.    0.27  0.    0.  ]\n",
            " [ 0.    0.    0.49  0.    0.  ]\n",
            " [ 0.    0.   -0.04  0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  2.67e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -7.19e-03  6.87e-03]\n",
            " [ 0.00e+00  0.00e+00  3.69e-01 -2.21e-03  2.19e-01]\n",
            " [ 0.00e+00  5.74e-03 -7.61e-03 -6.42e-03 -5.30e-03]\n",
            " [-2.27e-02 -6.38e-04  2.11e-01 -1.83e-03  4.31e-02]]\n",
            "[[ 1.20e-02  1.36e-01 -3.13e-01  1.29e-01  1.36e-02]\n",
            " [ 1.39e-01 -9.18e-01  1.64e+00 -9.13e-01  1.40e-01]\n",
            " [-3.71e-01  2.83e+00 -5.06e+00  2.84e+00 -3.76e-01]\n",
            " [ 1.55e-01 -9.66e-01  1.72e+00 -9.82e-01  1.61e-01]\n",
            " [ 9.32e-03  1.42e-01 -3.33e-01  1.54e-01  4.69e-03]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.60e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -7.19e-03  6.87e-03]\n",
            " [ 1.00e+00  0.00e+00  3.69e-01 -2.21e-03  2.19e-01]\n",
            " [ 0.00e+00  5.74e-03 -7.61e-03 -6.42e-03 -5.30e-03]\n",
            " [ 2.66e-02 -6.38e-04  2.11e-01 -1.83e-03  4.31e-02]]\n",
            "[[ 1.20e-02  1.36e-01 -3.47e-01  1.29e-01  1.36e-02]\n",
            " [ 1.39e-01 -9.18e-01  2.78e+00 -9.13e-01  1.40e-01]\n",
            " [-3.31e-01  1.67e+00 -5.02e+00  1.68e+00 -3.36e-01]\n",
            " [ 1.55e-01 -9.66e-01  2.86e+00 -9.82e-01  1.61e-01]\n",
            " [ 9.32e-03  1.42e-01 -3.67e-01  1.54e-01  4.69e-03]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.21  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.26  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.26]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.27e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.45e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-7.93e-10 -4.64e-10]\n",
            "SymNet parameters\n",
            "[[ 9.27e-13  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.74e-14  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-4.63e-14  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.73e-14  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[ 3.20e-12 -1.21e-13]\n",
            "SymNet parameters\n",
            "[[ 3.86e-14  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.12e-14  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.12e-16\n",
            "   1.13e-14]\n",
            " [ 7.97e-14  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.90e-14  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.28e-17\n",
            "   1.30e-13]]\n",
            "SymNet parameters\n",
            "[-1.03e-14 -1.21e-11]\n",
            "SymNet parameters\n",
            "[[-2.79e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.00e-12\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.14 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.14 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-9.61e-01  0.00e+00  0.00e+00  2.93e-01  0.00e+00  2.93e-01 -1.51e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   3.34e-13  1.18e-03  1.24e-06  7.46e-01]]\n",
            "SymNet parameters\n",
            "[1.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.61  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.28]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.43e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.91e-10  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-8.54e-10 -5.17e-10]\n",
            "SymNet parameters\n",
            "[[ 2.41e-13  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.05e-14  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-1.55e-12  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.83e-15  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-1.35e-11 -1.56e-12]\n",
            "SymNet parameters\n",
            "[[-1.33e-12  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.05e-13  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.60e-15\n",
            "  -4.84e-13]\n",
            " [-1.48e-11  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.47e-13  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.42e-15\n",
            "  -1.40e-12]]\n",
            "SymNet parameters\n",
            "[-6.91e-13 -1.24e-11]\n",
            "SymNet parameters\n",
            "[[-3.40e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.51e-15\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    1.88  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.41  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 1.85e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.93e-01  0.00e+00\n",
            "   0.00e+00  3.86e-01  0.00e+00  3.86e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -6.18e-13  3.47e-03 -1.59e-12 -4.28e-01]]\n",
            "SymNet parameters\n",
            "[0.42]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0442,  0.5782,  0.5066, 26.3397,  6.6314, 23.6708,  0.0531,  0.6648,\n",
            "         0.6760, 30.4864,  9.2510, 30.8737], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 277.446336\n",
            "         Iterations: 40\n",
            "         Function evaluations: 113\n",
            "         Gradient evaluations: 104\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.   -0.   -0.01]\n",
            " [ 0.    0.02  0.04 -0.04  0.05]\n",
            " [-0.01 -0.18 -0.56 -0.31 -0.55]\n",
            " [ 0.02 -0.07  0.06 -0.19  0.08]\n",
            " [ 0.01 -0.11 -0.29 -0.21 -0.18]]\n",
            "[[-0.11  0.28 -0.36  0.38 -0.19]\n",
            " [-0.11  0.59 -0.91  0.25  0.13]\n",
            " [ 0.51 -1.84  3.57 -1.21  0.07]\n",
            " [-0.34  1.07 -1.31  0.31  0.19]\n",
            " [ 0.04 -0.06 -0.05  0.3  -0.21]]\n",
            "[[ 0.00e+00  1.00e+00  0.00e+00 -5.10e-05  4.26e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.13 -0.84  0.26  0.5  -0.04]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-5.10e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 4.26e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.13  0.    0.  ]\n",
            " [ 0.    0.   -0.84  0.    0.  ]\n",
            " [ 0.    0.    0.26  0.    0.  ]\n",
            " [ 0.    0.    0.5   0.    0.  ]\n",
            " [ 0.    0.   -0.04  0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  3.80e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -5.82e-03  2.20e-03]\n",
            " [ 0.00e+00  0.00e+00  2.38e-01 -4.53e-03  1.27e-01]\n",
            " [ 0.00e+00  4.03e-03 -7.44e-03 -5.20e-03 -9.70e-03]\n",
            " [-1.18e-02 -6.89e-04  1.16e-01 -4.38e-03 -8.00e-03]]\n",
            "[[-0.02  0.19 -0.34  0.19 -0.02]\n",
            " [ 0.2  -0.96  1.57 -0.97  0.21]\n",
            " [-0.41  2.77 -4.79  2.79 -0.43]\n",
            " [ 0.22 -1.02  1.67 -1.05  0.23]\n",
            " [-0.03  0.21 -0.38  0.22 -0.03]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.23e-03]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -5.82e-03  2.20e-03]\n",
            " [ 1.00e+00  0.00e+00  2.38e-01 -4.53e-03  1.27e-01]\n",
            " [ 0.00e+00  4.03e-03 -7.44e-03 -5.20e-03 -9.70e-03]\n",
            " [ 3.38e-02 -6.89e-04  1.16e-01 -4.38e-03 -8.00e-03]]\n",
            "[[-0.02  0.19 -0.38  0.19 -0.02]\n",
            " [ 0.2  -0.96  2.72 -0.97  0.21]\n",
            " [-0.37  1.59 -4.76  1.62 -0.38]\n",
            " [ 0.22 -1.02  2.82 -1.05  0.23]\n",
            " [-0.03  0.21 -0.42  0.22 -0.03]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.19  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.03  0.26]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 7.04e-11 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 2.94e-11 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[6.75e-11 3.95e-11]\n",
            "SymNet parameters\n",
            "[[-7.89e-14  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.04e-15  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 3.94e-15  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.18e-15  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-2.72e-13  1.03e-14]\n",
            "SymNet parameters\n",
            "[[ 1.40e-15  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.70e-16  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.66e-17\n",
            "  -9.59e-16]\n",
            " [-6.68e-15  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.44e-15  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.79e-18\n",
            "  -1.11e-14]]\n",
            "SymNet parameters\n",
            "[-2.12e-15  1.03e-12]\n",
            "SymNet parameters\n",
            "[[-2.53e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  4.25e-13\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.15 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.12 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.01e+00  0.00e+00  0.00e+00  2.93e-01  0.00e+00  2.93e-01  2.43e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -2.84e-14  1.18e-03 -1.06e-07  7.16e-01]]\n",
            "SymNet parameters\n",
            "[1.02]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.61  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.27]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 4.62e-11 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 4.18e-11 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[7.26e-11 4.40e-11]\n",
            "SymNet parameters\n",
            "[[-2.05e-14  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.60e-15  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.32e-13  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.26e-16  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[1.15e-12 1.32e-13]\n",
            "SymNet parameters\n",
            "[[ 9.31e-14  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.59e-14  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.92e-16\n",
            "   4.12e-14]\n",
            " [ 1.26e-12  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.31e-14  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.17e-16\n",
            "   1.19e-13]]\n",
            "SymNet parameters\n",
            "[4.99e-14 1.05e-12]\n",
            "SymNet parameters\n",
            "[[-3.13e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  8.10e-16\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    1.88  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.41  0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 1.98e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.95e-01  0.00e+00\n",
            "   0.00e+00  3.88e-01  0.00e+00  3.88e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   5.26e-14  3.47e-03  1.36e-13 -4.28e-01]]\n",
            "SymNet parameters\n",
            "[0.41]\n",
            "utest_obs torch.Size([3, 2, 64, 64])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([12, 2, 64, 64])\n",
            "u_obs.abs().max()\n",
            "tensor(2.0666, dtype=torch.float64)\n",
            "v_obs.abs().max()\n",
            "tensor(5.3383, dtype=torch.float64)\n",
            "u_obs.abs().min()\n",
            "tensor(-1.2667, dtype=torch.float64)\n",
            "v_obs.abs().min()\n",
            "tensor(1.9809, dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor([ 0.0442,  0.5781,  0.5065, 25.5573,  6.6314, 23.0183,  0.0532,  0.6646,\n",
            "         0.6758, 29.5615,  9.2510, 30.1011], dtype=torch.float64,\n",
            "       grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor([0.0423, 0.0508], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 338.831965\n",
            "         Iterations: 50\n",
            "         Function evaluations: 108\n",
            "         Gradient evaluations: 97\n",
            "convolution moment and kernels\n",
            "[[ 1.    0.    0.01  0.    0.  ]\n",
            " [ 0.    0.    0.02 -0.05  0.04]\n",
            " [ 0.   -0.14 -0.43 -0.24 -0.42]\n",
            " [ 0.02 -0.06  0.02 -0.14  0.05]\n",
            " [ 0.02 -0.09 -0.22 -0.17 -0.12]]\n",
            "[[-0.05  0.12 -0.15  0.22 -0.13]\n",
            " [-0.18  0.77 -1.11  0.43  0.04]\n",
            " [ 0.51 -1.82  3.54 -1.27  0.15]\n",
            " [-0.31  1.03 -1.34  0.44  0.09]\n",
            " [ 0.04 -0.1   0.05  0.18 -0.15]]\n",
            "[[ 0.00e+00  1.00e+00  0.00e+00 -2.79e-05  3.69e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.12 -0.81  0.22  0.52 -0.05]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-2.79e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 3.69e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "[[ 0.    0.    0.12  0.    0.  ]\n",
            " [ 0.    0.   -0.81  0.    0.  ]\n",
            " [ 0.    0.    0.22  0.    0.  ]\n",
            " [ 0.    0.    0.52  0.    0.  ]\n",
            " [ 0.    0.   -0.05  0.    0.  ]]\n",
            "[[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  4.29e-02]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -6.72e-03  1.81e-03]\n",
            " [ 0.00e+00  0.00e+00  1.87e-01 -3.69e-03  9.02e-02]\n",
            " [ 0.00e+00  2.83e-03 -6.97e-03 -7.18e-03 -9.81e-03]\n",
            " [ 2.09e-03 -5.13e-04  8.45e-02 -2.75e-03 -2.67e-02]]\n",
            "[[-0.04  0.21 -0.35  0.21 -0.03]\n",
            " [ 0.22 -0.99  1.52 -0.99  0.23]\n",
            " [-0.43  2.75 -4.64  2.76 -0.43]\n",
            " [ 0.24 -1.05  1.62 -1.07  0.25]\n",
            " [-0.04  0.24 -0.4   0.25 -0.05]]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[ 0.01 -0.06  0.    0.06 -0.01]\n",
            " [-0.06  0.44  0.   -0.44  0.06]\n",
            " [ 0.    0.    0.    0.    0.  ]\n",
            " [ 0.06 -0.44  0.    0.44 -0.06]\n",
            " [-0.01  0.06  0.   -0.06  0.01]]\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.58e-03]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -6.72e-03  1.81e-03]\n",
            " [ 1.00e+00  0.00e+00  1.87e-01 -3.69e-03  9.02e-02]\n",
            " [ 0.00e+00  2.83e-03 -6.97e-03 -7.18e-03 -9.81e-03]\n",
            " [ 4.23e-02 -5.13e-04  8.45e-02 -2.75e-03 -2.67e-02]]\n",
            "[[-0.04  0.21 -0.4   0.21 -0.03]\n",
            " [ 0.22 -0.99  2.7  -0.99  0.23]\n",
            " [-0.38  1.57 -4.62  1.58 -0.39]\n",
            " [ 0.24 -1.05  2.79 -1.07  0.25]\n",
            " [-0.04  0.24 -0.44  0.25 -0.05]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-4.19  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.26]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 2.11e-12 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 8.80e-13 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[2.02e-12 1.18e-12]\n",
            "SymNet parameters\n",
            "[[-2.36e-15  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.21e-16  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.18e-16  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.51e-17  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-8.15e-15  3.08e-16]\n",
            "SymNet parameters\n",
            "[[-1.16e-16  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.28e-16  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.96e-19\n",
            "  -2.87e-17]\n",
            " [-2.00e-16  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.11e-16  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -8.36e-20\n",
            "  -3.32e-16]]\n",
            "SymNet parameters\n",
            "[-2.23e-16  3.09e-14]\n",
            "SymNet parameters\n",
            "[[-1.68e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.27e-14\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.15 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.13 0.   0.\n",
            "  0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-9.88e-01  0.00e+00  0.00e+00  2.95e-01  0.00e+00  2.95e-01 -2.25e-03  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "  -8.50e-16  1.18e-03 -3.16e-09  7.14e-01]]\n",
            "SymNet parameters\n",
            "[1.01]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.61  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01  0.27]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.38e-12 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.25e-12 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[2.18e-12 1.32e-12]\n",
            "SymNet parameters\n",
            "[[-6.13e-16  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.78e-17  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 3.96e-15  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.76e-18  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[3.45e-14 3.97e-15]\n",
            "SymNet parameters\n",
            "[[ 2.87e-15  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.05e-15  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.17e-17\n",
            "   1.23e-15]\n",
            " [ 3.77e-14  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.41e-16  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.15e-17\n",
            "   3.58e-15]]\n",
            "SymNet parameters\n",
            "[1.41e-15 3.14e-14]\n",
            "SymNet parameters\n",
            "[[-2.28e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.43e-17\n",
            "   0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.    1.87  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.4   0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 1.55e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.95e-01  0.00e+00\n",
            "   0.00e+00  3.91e-01  0.00e+00  3.91e-01  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.57e-15  3.47e-03  4.06e-15 -4.30e-01]]\n",
            "SymNet parameters\n",
            "[0.41]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import sys,time\n",
        "import numpy as np\n",
        "import torch\n",
        "import timeout_decorator\n",
        "from aTEAM.optim import NumpyFunctionInterface #NFI_ex21d1\n",
        "from scipy.optimize.lbfgsb import fmin_l_bfgs_b as lbfgsb\n",
        "from scipy.optimize.slsqp import fmin_slsqp as slsqp\n",
        "from scipy.optimize import fmin_bfgs as bfgs\n",
        "import conf\n",
        "\n",
        "\n",
        "\n",
        "import setenv21d1 as setenv\n",
        "\n",
        "import initparameters_ex21d1 as initparameters\n",
        "\n",
        "kw = {\n",
        "          '--name':'Murrayll28',\n",
        "#         '--dtype':'double',\n",
        "#         '--device':'cuda:0',\n",
        "          '--constraint':'2',\n",
        "#         # computing region\n",
        "          '--eps':2*5, #2*np.pi,\n",
        "         '--dt':1e-2/4,\n",
        "#         '--cell_num':1,\n",
        "          '--blocks':'0-6,9,12,15',\n",
        "#         # super parameters of network\n",
        "          '--kernel_size':5,\n",
        "#         '--max_order':2,\n",
        "          '--dx':2*5/64,#2*np.pi/32,\n",
        "          '--hidden_layers':8,\n",
        "#         '--scheme':'upwind',\n",
        "#         # data generator\n",
        "          '--dataname':'Murrayll28',\n",
        "#         '--viscosity':0.05,\n",
        "          '--zoom':1,\n",
        "          '--max_dt':1/1600,\n",
        "          '--batch_size':12,\n",
        "#         '--data_timescheme':'rk2',\n",
        "#         '--channel_names':'u,v',\n",
        "         '--freq':13,\n",
        "          '--data_start_time':0,\n",
        "#         # data transform\n",
        "          '--start_noise':0.05,\n",
        "          '--end_noise':0.05,#0.0,\n",
        "        #   '--stablize':4.21e-08,#noise 0\n",
        "        #  '--sparsity':0.000799,\n",
        "        #  '--momentsparsity':0.000546,\n",
        "         '--stablize':5.46e-05,#005\n",
        "         '--sparsity':4.93e-05,\n",
        "         '--momentsparsity':3.28e-05,\n",
        "        #  '--npseed':-1,\n",
        "        #  '--torchseed':-1,\n",
        "          '--maxiter':2000,\n",
        "#         '--recordfile':'None',\n",
        "          '--recordcycle':200,\n",
        "#         '--savecycle':-1,\n",
        "#         '--start_from':-1,\n",
        "          '--mesh_size': [64, 64],\n",
        "          \"--boundary_condition\": \"Neumann\",\n",
        "          \"--lower_bound\": -5,\n",
        "          \"--upper_bound\": 5,\n",
        "          \"--dim\":\"2d\",\n",
        "\n",
        "\n",
        "\n",
        "          }\n",
        "options = conf.setoptions(argv=sys.argv[1:],kw=kw,configfile=None)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    options['--device'] = 'cuda'\n",
        "else:\n",
        "    options['--device'] = 'cpu'\n",
        "\n",
        "globalnames, callback, model, data_model, sampling, addnoise,addnoiset = setenv.setenv(options)\n",
        "globals().update(globalnames)\n",
        "\n",
        "\n",
        "torch.cuda.manual_seed_all(torchseed)\n",
        "torch.manual_seed(torchseed)\n",
        "np.random.seed(npseed)\n",
        "\n",
        "# initialization of parameters\n",
        "if start_from<0:\n",
        "\n",
        "    initparameters.initkernels(model, scheme=scheme)\n",
        "\n",
        "    initparameters.initexpr(model, viscosity=viscosity, pattern='random')\n",
        "\n",
        "else: # load checkpoint of layer-$start_from\n",
        "    callback.load(start_from, iternum='final')\n",
        "ftestloss=[]\n",
        "tu_obs,tu_true,tu = \\\n",
        "        setenv.data(model,data_model,globalnames,sampling,addnoise,blocks[-1],data_start_time)\n",
        "tutest_obs,tutest_true,tutest = \\\n",
        "    setenv.cvtestdata(model,data_model,globalnames,sampling,addnoiset,blocks[-1],data_start_time)\n",
        "\n",
        "#%% train\n",
        "for block in blocks:\n",
        "    trainlossf=[]\n",
        "    testlossf=[]\n",
        "    if block<=start_from:\n",
        "        continue\n",
        "    r = np.random.randn()+torch.randn(1,dtype=torch.float64,device=device).item()\n",
        "    with callback.open() as output:\n",
        "        print('device: ', device, file=output)\n",
        "        print('generate a random number to check random seed: ', r, file=output)\n",
        "    if block == 0:\n",
        "        callback.stage = 'warmup'\n",
        "        isfrozen = (False if constraint == 'free' else True)\n",
        "        #isfrozen = False\n",
        "    else:\n",
        "        callback.stage = 'block-'+str(block)\n",
        "        isfrozen = False\n",
        "        if constraint == 'frozen':\n",
        "            isfrozen = True\n",
        "    stepnum = block if block>=1 else 1\n",
        "    layerweight = [1,]*stepnum\n",
        "\n",
        "\n",
        "    u_obs,u_true,u = \\\n",
        "        tu_obs[:stepnum+1],tu_true[:stepnum+1],tu[:stepnum+1]\n",
        "    utest_obs,utest_true,utest = \\\n",
        "        tutest_obs[:stepnum+1],tutest_true[:stepnum+1],tutest[:stepnum+1]\n",
        "    print(\"utest_obs\", utest_obs[0].shape)\n",
        "    print(\"u_obs shape: batchsize x channelNum x xgridsize x ygridsize\")\n",
        "    print(u_obs[0].shape)\n",
        "    print(\"u_obs.abs().max()\")\n",
        "    print(u_obs[0][:,0,:].abs().max())\n",
        "    print(\"v_obs.abs().max()\")\n",
        "    print(u_obs[0][:,1,:].abs().max())\n",
        "    print(\"u_obs.abs().min()\")\n",
        "    print(u_obs[0][:,0,:].min())\n",
        "    print(\"v_obs.abs().min()\")\n",
        "    print(u_obs[0][:,1,:].min())\n",
        "    print(\"u_lib variance\")\n",
        "    print(initparameters.trainvar(model.UInputs(u_obs[0])))\n",
        "\n",
        "    print(\"u_obs variance\")\n",
        "    print(initparameters.trainvar(u_obs[0]))\n",
        "\n",
        "    # set NumpyFunctionInterface\n",
        "    def forward():\n",
        "        stableloss,dataloss,sparseloss,momentloss, testloss = \\\n",
        "                setenv.loss(model, u_obs, utest_obs, globalnames, block, layerweight)\n",
        "        layersparsity=0\n",
        "        if block == 0:\n",
        "            # for stage='warmup', no regularization term used\n",
        "            loss = dataloss\n",
        "        else:\n",
        "            loss = stablize*stableloss+dataloss+stepnum*sparsity*sparseloss+stepnum*momentsparsity*momentloss#+stepnum*layersparsity*lastlayerloss\n",
        "        if constraint == 'frozen':\n",
        "            momentloss = 0\n",
        "\n",
        "            loss = stablize*stableloss+dataloss+stepnum*sparsity*sparseloss+stepnum*momentsparsity*momentloss#+stepnum*layersparsity*lastlayerloss\n",
        "\n",
        "        if torch.isnan(loss):\n",
        "            loss = (torch.ones(1,requires_grad=True)/torch.zeros(1)).to(loss)\n",
        "\n",
        "        tloss=testloss\n",
        "\n",
        "\n",
        "\n",
        "        testlossf.append(tloss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    nfi = NumpyFunctionInterface([\n",
        "        dict(params=model.diff_params(), isfrozen=isfrozen,\n",
        "            x_proj=model.diff_x_proj, grad_proj=model.diff_grad_proj),\n",
        "        dict(params=model.expr_params(),\n",
        "            isfrozen=False)\n",
        "        ], forward=forward, always_refresh=False,block=block, tol=1)\n",
        "    callback.nfi = nfi\n",
        "\n",
        "    def callbackhook(_callback, *args):\n",
        "        # global model,block,u0_obs,T,stable_loss,data_loss,sparse_loss\n",
        "        stableloss,dataloss,sparseloss,momentloss, testloss = \\\n",
        "                setenv.loss(model, u_obs, utest_obs, globalnames, block, layerweight)\n",
        "        stableloss,dataloss,sparseloss,momentloss = \\\n",
        "                stableloss.item(),dataloss.item(),sparseloss.item(),momentloss.item()\n",
        "        with _callback.open() as output:\n",
        "            print(\"stableloss: {:.2e}\".format(stableloss), \"  dataloss: {:.2e}\".format(dataloss),\n",
        "                    \"  sparseloss: {:.2e}\".format(sparseloss), \"momentloss: {:.2e}\".format(momentloss),\n",
        "                    file=output)\n",
        "        return None\n",
        "    callbackhookhandle = callback.register_hook(callbackhook)\n",
        "    if block == 0:\n",
        "        callback.save(nfi.flat_param, 'start')\n",
        "    try:\n",
        "\n",
        "        # optimize\n",
        "        xopt = bfgs(nfi.f,nfi.flat_param,nfi.fprime,gtol=2e-16,maxiter=maxiter, callback=callback)\n",
        "        # xopt,f,d = lbfgsb(nfi.f, nfi.flat_param, nfi.fprime, m=maxiter, callback=callback, factr=1e7, pgtol=1e-8,maxiter=maxiter,iprint=0)\n",
        "        np.set_printoptions(precision=2, linewidth=90)\n",
        "        print(\"convolution moment and kernels\")\n",
        "        for k in range(max_order+1):\n",
        "            for j in range(k+1):\n",
        "                print((model.__getattr__('fd'+str(j)+str(k-j)).moment).data.cpu().numpy())\n",
        "                print((model.__getattr__('fd'+str(j)+str(k-j)).kernel).data.cpu().numpy())\n",
        "        for p in model.expr_params():\n",
        "            print(\"SymNet parameters\")\n",
        "            print(p.data.cpu().numpy())\n",
        "    except RuntimeError as Argument:\n",
        "        with callback.open() as output:\n",
        "            print(Argument, file=output) # if overflow then just print and continue\n",
        "    finally:\n",
        "        # save parameters\n",
        "        nfi.flat_param = xopt\n",
        "        callback.save(xopt, 'final')\n",
        "        with callback.open() as output:\n",
        "            print('finally, finish this stage', file=output)\n",
        "        callback.record(xopt, callback.ITERNUM)\n",
        "        callbackhookhandle.remove()\n",
        "        @timeout_decorator.timeout(800)\n",
        "        def printcoeffs():\n",
        "            with callback.open() as output:\n",
        "                print('current expression:', file=output)\n",
        "                for poly in model.polys:\n",
        "                    tsym,csym = poly.coeffs()\n",
        "                    print(tsym[:20], file=output)\n",
        "                    print(csym[:20], file=output)\n",
        "        try:\n",
        "            printcoeffs()\n",
        "        except timeout_decorator.TimeoutError:\n",
        "            with callback.open() as output:\n",
        "                print('Time out', file=output)\n",
        "\n",
        "    ftestloss.append(testlossf)\n",
        "\n",
        "\n",
        "with callback.open() as output:\n",
        "    print(\"u_obs.abs().max()\", file=output)\n",
        "    print(u_obs[0][:,0,:].abs().max(), file=output)\n",
        "    print(\"v_obs.abs().max()\", file=output)\n",
        "    print(u_obs[0][:,1,:].abs().max(), file=output)\n",
        "with torch.no_grad():\n",
        "    with callback.open() as output:\n",
        "        print(\"model(u_obs[0],T=20*dt).abs().max()\", file=output)\n",
        "        print(model(u_obs[0], T=20*dt).abs().max(), file=output)\n",
        "        print(\"model(u_obs[0],T=30*dt).abs().max()\", file=output)\n",
        "        print(model(u_obs[0], T=30*dt).abs().max(), file=output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieve Coefficients and terms from Trained mFrac-PDE-Net Model\n"
      ],
      "metadata": {
        "id": "QHPAR7MtU4ux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RWVBDErgGAG1"
      },
      "outputs": [],
      "source": [
        "from sympy.parsing.sympy_parser import parse_expr\n",
        "from sympy import symbols, lambdify\n",
        "def givevals(dic, setexp):\n",
        "  u00=\"u00\"\n",
        "  v00=\"v00\"\n",
        "  lnu=\"lnu\"\n",
        "  I=\"I\"\n",
        "\n",
        "  newlist={}\n",
        "  for expr in list(setexp.keys()):\n",
        "    #print(expr)\n",
        "    dim=64*64*15\n",
        "    if expr == 1:\n",
        "        newlist[expr]=np.ones((dim,1))\n",
        "    elif u00 in str(expr) and v00 in str(expr):\n",
        "      #print(expr)\n",
        "      f = lambdify({u00,v00}, expr)\n",
        "      finalf=f(dic[u00][:,0],dic[v00][:,0])\n",
        "      newlist[expr]=finalf.reshape((dim,1))\n",
        "    elif u00 in str(expr) and v00 not in str(expr):\n",
        "      #print(expr)\n",
        "      f = lambdify(u00, expr)\n",
        "      finalf=f(dic[u00][:,0])\n",
        "      newlist[expr]=finalf.reshape((dim,1))\n",
        "    elif u00 not in str(expr) and v00 in str(expr):\n",
        "      #print(expr)\n",
        "      f = lambdify(v00, expr)\n",
        "      finalf=f(dic[v00][:,0])\n",
        "      newlist[expr]=finalf.reshape((dim,1))\n",
        "    elif \"exp\"  in str(expr) and \"I\" not in str(expr):\n",
        "      f = lambdify(lnu, expr)\n",
        "      finalf=f(dic[lnu][:,0])\n",
        "      newlist[expr]=finalf.reshape((dim,1))\n",
        "    elif \"exp\"  in str(expr) and \"I\" in str(expr):\n",
        "      f = lambdify({lnu,I}, expr)\n",
        "      finalf=f(channel_dic[lnu][:,0],channel_dic[I][:,0])\n",
        "      newlist[expr]=finalf.reshape((dim,1))\n",
        "\n",
        "    else:\n",
        "      for i in list(dic.keys()):\n",
        "        if str(i) == str(expr):\n",
        "          newlist[expr]=dic[i]\n",
        "  return newlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YSsEF2iFhzwP"
      },
      "outputs": [],
      "source": [
        "#no parsity\n",
        "termunosp={}\n",
        "termvnosp={}\n",
        "termunospc={}\n",
        "termvnospc={}\n",
        "\n",
        "#l2 norm\n",
        "termul2={}\n",
        "termvl2={}\n",
        "termul2c={}\n",
        "termvl2c={}\n",
        "\n",
        "#sparsity\n",
        "termusp={}\n",
        "termvsp={}\n",
        "termuspc={}\n",
        "termvspc={}\n",
        "\n",
        "terms0 = []\n",
        "terms1 = []\n",
        "\n",
        "options = {}\n",
        "options['--name'] = 'Murrayll28'\n",
        "configfile=\"checkpoint\"+\"/\"+options['--name']+'/options.yaml'\n",
        "options = conf.setoptions(argv=None,kw=None,configfile=configfile,isload=True)\n",
        "options['--device'] = 'cpu'\n",
        "block = 15\n",
        "\n",
        "globalnames, callback, model, data_model, sampling, addnoise, addnoiset = setenv.setenv(options)\n",
        "\n",
        "callback.load(int(block))\n",
        "\n",
        "tsym,csym = model.poly0.coeffs(calprec=6)\n",
        "terms0 = tsym[:40]\n",
        "coeffs0 = np.zeros((len(terms0)))\n",
        "coeffs0[:min(len(tsym),40)] = csym[:min(len(tsym),40)]\n",
        "tsym,csym = model.poly1.coeffs(calprec=6)\n",
        "terms1 = tsym[:40]\n",
        "coeffs1 = np.zeros((len(terms1)))\n",
        "coeffs1[:min(len(tsym),40)] = csym[:min(len(tsym),40)]\n",
        "torch.save(dict(terms0=terms0,terms1=terms1,coeffs0=coeffs0,coeffs1=coeffs1),'-block-000-'+str(block))\n",
        "lib=torch.load(\"-block-000-15\")\n",
        "\n",
        "\n",
        "l1=lib['terms0']\n",
        "l2=lib['terms1']\n",
        "coe1=lib['coeffs0']\n",
        "coe2=lib['coeffs1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj0M9eMJOYlA",
        "outputId": "acadc7a1-9bf1-424a-9034-fa1e02b124c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initgenb\n",
            "t=0.0e+00\n",
            "t=1.0e-02\n",
            "t=2.0e-02\n",
            "t=3.0e-02\n",
            "t=4.0e-02\n",
            "t=5.0e-02\n",
            "t=6.0e-02\n",
            "t=7.0e-02\n",
            "t=8.0e-02\n",
            "t=9.0e-02\n",
            "t=1.0e-01\n",
            "t=1.1e-01\n",
            "t=1.2e-01\n",
            "t=1.3e-01\n",
            "t=1.4e-01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ea021df2e01b>:17: SymPyDeprecationWarning: \n",
            "\n",
            "Passing the function arguments to lambdify() as a set is deprecated. This\n",
            "leads to unpredictable results since sets are unordered. Instead, use a list\n",
            "or tuple for the function arguments.\n",
            "\n",
            "See https://docs.sympy.org/latest/explanation/active-deprecations.html#deprecated-lambdify-arguments-set\n",
            "for details.\n",
            "\n",
            "This has been deprecated since SymPy version 1.6.3. It\n",
            "will be removed in a future version of SymPy.\n",
            "\n",
            "  f = lambdify({u00,v00}, expr)\n"
          ]
        }
      ],
      "source": [
        "simulation=1\n",
        "sim=0\n",
        "termuc={}\n",
        "termvc={}\n",
        "\n",
        "for order, ele in enumerate(l1):\n",
        "  if \"/\" not in str(ele):\n",
        "    termuc[ele]=1\n",
        "\n",
        "for order, ele in enumerate(l2):\n",
        "  if \"/\" not in str(ele):\n",
        "    termvc[ele]=1\n",
        "\n",
        "if len(termunosp)==0:\n",
        "  termunosp={i:[0]*simulation for i in l1}\n",
        "  termvnosp={i:[0]*simulation for i in l2}\n",
        "  for order, ele in enumerate(l1):\n",
        "    termunosp[ele][sim]=round(coe1[order],5)\n",
        "  for order, ele in enumerate(l2):\n",
        "    termvnosp[ele][sim]=round(coe2[order],5)\n",
        "  termunospc.update(termuc)\n",
        "  termvnospc.update(termvc)\n",
        "\n",
        "else:\n",
        "  for order, ele in enumerate(l1):\n",
        "    if ele in list(termunosp.keys()):\n",
        "      termunosp[ele][sim]=round(coe1[order],5)\n",
        "    else:\n",
        "      termunosp[ele]=[0]*simulation\n",
        "      termunosp[ele][sim]=round(coe1[order],5)\n",
        "\n",
        "  for order, ele in enumerate(l2):\n",
        "    if ele in list(termvnosp.keys()):\n",
        "      termvnosp[ele][sim]=round(coe2[order],5)\n",
        "    else:\n",
        "      termvnosp[ele]=[0]*simulation\n",
        "      termvnosp[ele][sim]=round(coe2[order],5)\n",
        "  for order, item in enumerate(list(termuc)):\n",
        "    if item in list(termunospc.keys()):\n",
        "      termunospc[item]+=termuc[item]\n",
        "\n",
        "    else:\n",
        "      termunospc[item]=termuc[item]\n",
        "  for order, item in enumerate(termvc):\n",
        "    if item in list(termvnospc.keys()):\n",
        "      termvnospc[item]+=termvc[item]\n",
        "\n",
        "    else:\n",
        "      termvnospc[item]=termvc[item]\n",
        "\n",
        "T = 1e-2\n",
        "_,_,u = setenv.data(model,data_model,globalnames,sampling,addnoise,block=1,data_start_time=0)\n",
        "init = u[0]\n",
        "x0 = init\n",
        "\n",
        "\n",
        "\n",
        "x1=x0\n",
        "xtemp=np.zeros((15,12,64,64))\n",
        "utemp=np.zeros((15,2,64,64))\n",
        "\n",
        "for t in range(15):\n",
        "    print('t={:.1e}'.format(t*T))\n",
        "\n",
        "    startt = time.time()\n",
        "    with torch.no_grad():\n",
        "        x1 = data_model.predict(x1, T=T)\n",
        "        _,x41 = addnoise(x0,x1)\n",
        "        xtmp4, ut = model.predict_val(x41,T)\n",
        "        xtmp4=xtmp4[:1,...,...]\n",
        "        ut=ut[:1,...,...]\n",
        "        xtemp[t,:,:,:]=xtmp4.data.cpu().numpy()\n",
        "        utemp[t,:,:,:]=ut.data.cpu().numpy()\n",
        "\n",
        "\n",
        "        #print(\"x1\", x1)\n",
        "    stopt = time.time()\n",
        "\n",
        "\n",
        "allchannels = []\n",
        "channel_names=model.channel_names\n",
        "max_order=2\n",
        "\n",
        "for c in channel_names:\n",
        "      for k in range(max_order+1):\n",
        "          for j in range(k+1):\n",
        "              allchannels.append(c+str(j)+str(k-j))\n",
        "\n",
        "\n",
        "xnew=xtemp\n",
        "\n",
        "  #get matrix of X\n",
        "channel_dic={}\n",
        "for order, ele in enumerate(xnew[0]):\n",
        "    channel_dic[allchannels[order]]=xnew[:,order,:,:].T.reshape(64*64*15,1)\n",
        "\n",
        "rhsu={i:0 for i in l1}\n",
        "rhsv={i:0 for i in l2}\n",
        "\n",
        "rhu1=givevals(channel_dic, rhsu)\n",
        "rhv1=givevals(channel_dic, rhsv)\n",
        "\n",
        "u20=symbols(\"u20\")\n",
        "u02=symbols(\"u02\")\n",
        "v20=symbols(\"v20\")\n",
        "v02=symbols(\"v02\")\n",
        "nt=u20+u02\n",
        "rhu11=rhu1.copy()\n",
        "\n",
        "indu20=l1.index(u20)\n",
        "indu02=l1.index(u02)\n",
        "rhu11[nt]=rhu11.pop(u20)\n",
        "rhu11[nt]=rhu11[nt]+rhu11[u02]\n",
        "l1[indu20]=l1[indu20]+l1[indu02]\n",
        "l1.remove(l1[indu02])\n",
        "\n",
        "nt=v20+v02\n",
        "rhv11=rhv1\n",
        "\n",
        "indv20=l2.index(v20)\n",
        "indv02=l2.index(v02)\n",
        "rhv11[nt]=rhv11.pop(v20)\n",
        "rhv11[nt]=rhv11[nt]+rhv11[v02]\n",
        "rhv11.pop(v02)\n",
        "l2[indv20]=l2[indv20]+l2[indv02]\n",
        "l2.remove(l2[indv02])\n",
        "\n",
        "dataMatrixu = np.array([rhu11[i] for i in l1])\n",
        "dataMatrixv = np.array([rhv11[i] for i in l2])\n",
        "\n",
        "linear_matu=dataMatrixu.T.reshape((64*64*15,len(l1)))\n",
        "linear_matv=dataMatrixv.T.reshape((64*64*15,len(l2)))\n",
        "\n",
        "coefu=coeffs0\n",
        "coefv=coeffs1\n",
        "coefu=np.delete(coefu,indu20)\n",
        "coefv=np.delete(coefv,indv20)\n",
        "coefu=np.reshape(coefu, (-1,1))\n",
        "coefv=np.reshape(coefv, (-1,1))\n",
        "# linear_matu1=np.round(linear_matu,4)\n",
        "# linear_matv1=np.round(linear_matv,4)\n",
        "\n",
        "uut=linear_matu@coefu\n",
        "uvt=linear_matv@coefv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqtQ_UBjVMVw",
        "outputId": "2cc75641-1909-4ac9-b72b-3d7e89abf2d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: [1.01212],\n",
              " u00: [-0.98806],\n",
              " u00*v00/(1.0*u00**2 + 0.25488950789362*u00 + 0.257304836935724): [-0.50826],\n",
              " u20: [0.29521],\n",
              " u02: [0.29521],\n",
              " v00: [-0.0022],\n",
              " v00/(1.0*u00**2 + 0.25488950789362*u00 + 0.257304836935724): [-0.00126]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "termunosp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr5RZhHoXCbh",
        "outputId": "58ecf90f-474d-49bd-bc33-434e30a7ed0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{u00*v00/(1.0*u00**2 + 0.252608602212288*u00 + 0.266239556147262): [-0.52235],\n",
              " 1: [0.40524],\n",
              " v20: [0.39134],\n",
              " v02: [0.39134],\n",
              " v00: [-0.19456],\n",
              " u00: [0.01553],\n",
              " v00/(1.0*u00**2 + 0.252608602212288*u00 + 0.266239556147262): [-0.00256]}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "termvnosp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$L^2$ norm slection criterion"
      ],
      "metadata": {
        "id": "7sd7TuL9XOxs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OrCp6DnvY3wi"
      },
      "outputs": [],
      "source": [
        "l2normu=np.sum(np.abs(linear_matu.T)**2,axis=-1)**(1./2)\n",
        "l2normu1=l2normu.reshape((len(l2normu),1))\n",
        "scalu=l2normu1*coefu\n",
        "\n",
        "\n",
        "indtermusp=[]\n",
        "for order,ele in enumerate(scalu):\n",
        "  if abs(ele)>max(abs(scalu))/50:\n",
        "\n",
        "    indtermusp.append(order)\n",
        "\n",
        "luspy=[]\n",
        "for i in indtermusp:\n",
        "  luspy.append(l1[i])\n",
        "\n",
        "\n",
        "#v\n",
        "l2normv=np.sum(np.abs(linear_matv.T)**2,axis=-1)**(1./2)\n",
        "l2normv1=l2normv.reshape((len(l2normv),1))\n",
        "scalv=l2normv1*coefv\n",
        "\n",
        "\n",
        "indtermvsp=[]\n",
        "for order,ele in enumerate(scalv):\n",
        "  if abs(ele)>max(abs(scalv))/50:\n",
        "\n",
        "    indtermvsp.append(order)\n",
        "\n",
        "lvspy=[]\n",
        "for i in indtermvsp:\n",
        "  lvspy.append(l2[i])\n",
        "\n",
        "termuc={}\n",
        "termvc={}\n",
        "\n",
        "for order, ele in enumerate(luspy):\n",
        "  if \"/\" not in str(ele):\n",
        "    termuc[ele]=1\n",
        "\n",
        "for order, ele in enumerate(lvspy):\n",
        "  if \"/\" not in str(ele):\n",
        "    termvc[ele]=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if len(termul2)==0:\n",
        "  termul2={i:[0]*simulation for i in luspy}\n",
        "  termvl2={i:[0]*simulation for i in lvspy}\n",
        "  for order, ele in enumerate(luspy):\n",
        "    order1=indtermusp[order]\n",
        "    termul2[ele][sim]=round(coefu[order1][0],5)\n",
        "  for order, ele in enumerate(lvspy):\n",
        "    order1=indtermvsp[order]\n",
        "    termvl2[ele][sim]=round(coefv[order1][0],5)\n",
        "  termul2c.update(termuc)\n",
        "  termvl2c.update(termvc)\n",
        "else:\n",
        "\n",
        "  for order, ele in enumerate(luspy):\n",
        "    if ele in list(termul2.keys()):\n",
        "      order1=indtermusp[order]\n",
        "      termul2[ele][sim]=round(coefu[order1][0],5)\n",
        "    else:\n",
        "      termul2[ele]=[0]*simulation\n",
        "      order1=indtermusp[order]\n",
        "      termul2[ele][sim]=round(coefu[order1][0],5)\n",
        "\n",
        "\n",
        "\n",
        "  for order, ele in enumerate(lvspy):\n",
        "    if ele in list(termvl2.keys()):\n",
        "      order1=indtermvsp[order]\n",
        "      termvl2[ele][sim]=round(coefv[order1][0],5)\n",
        "    else:\n",
        "      termvl2[ele]=[0]*simulation\n",
        "      order1=indtermvsp[order]\n",
        "      termvl2[ele][sim]=round(coefv[order1][0],5)\n",
        "  for order, item in enumerate(list(termuc.keys())):\n",
        "    if item in list(termul2c.keys()):\n",
        "      termul2c[item]+=termuc[item]\n",
        "\n",
        "    else:\n",
        "      termul2c[item]=termuc[item]\n",
        "  for order, item in enumerate(list(termvc.keys())):\n",
        "    if item in list(termvl2c.keys()):\n",
        "      termvl2c[item]+=termvc[item]\n",
        "\n",
        "    else:\n",
        "      termvl2c[item]=termvc[item]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyHqflT8VvbT",
        "outputId": "9ecaa807-1f15-4d95-9b60-4845b302def0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{u00*v00/(1.0*u00**2 + 0.252608602212288*u00 + 0.266239556147262): [-0.52235],\n",
              " 1: [0.40524],\n",
              " v02 + v20: [0.39134],\n",
              " v00: [-0.19456]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "termvl2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "termul2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZIVXRtQjAxi",
        "outputId": "36814dfd-ffc8-406c-b262-22e0121dbc30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: [1.01212],\n",
              " u00: [-0.98806],\n",
              " u00*v00/(1.0*u00**2 + 0.25488950789362*u00 + 0.257304836935724): [-0.50826],\n",
              " u02 + u20: [0.29521]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qdAP8NzWZex0"
      },
      "outputs": [],
      "source": [
        "dataMatrixuy = np.array([rhu11[i] for i in luspy])\n",
        "\n",
        "linear_matuy=dataMatrixuy.T.reshape((64*64*15,len(luspy)))\n",
        "\n",
        "\n",
        "coefuspy=[]\n",
        "\n",
        "for i in indtermusp:\n",
        "  coefuspy.append(coefu[i])\n",
        "\n",
        "linear_matuf1=np.round(linear_matuy,4)\n",
        "\n",
        "coefuspy=np.reshape(coefuspy, (-1,1))\n",
        "\n",
        "#v\n",
        "dataMatrixvy = np.array([rhv11[i] for i in lvspy ])\n",
        "\n",
        "linear_matvy=dataMatrixvy.T.reshape((64*64*15,len(lvspy)))\n",
        "\n",
        "\n",
        "coefvspy=[]\n",
        "\n",
        "for i in indtermvsp:\n",
        "  coefvspy.append(coefv[i])\n",
        "\n",
        "linear_matvf1=np.round(linear_matvy,4)\n",
        "\n",
        "coefvspy=np.reshape(coefvspy, (-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sparsity"
      ],
      "metadata": {
        "id": "Q9jWXsGkXe3n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pEBea0Ds5KGm"
      },
      "outputs": [],
      "source": [
        "def TrainSTRidge(R, Ut, bestu,lam, d_tol, maxit = 35, STR_iters = 30, l0_penalty = None, normalize = 2, split = 0.8, print_best_tol = False):\n",
        "    \"\"\"\n",
        "    This function trains a predictor using STRidge.\n",
        "    It runs over different values of tolerance and trains predictors on a training set, then evaluates them\n",
        "    using a loss function on a holdout set.\n",
        "    Please note published article has typo.  Loss function used here for model selection evaluates fidelity using 2-norm,\n",
        "    not squared 2-norm.\n",
        "    \"\"\"\n",
        "\n",
        "    # Split data into 80% training and 20% test, then search for the best tolderance.\n",
        "    np.random.seed(0) # for consistancy\n",
        "    n,_ = R.shape\n",
        "    train = np.random.choice(n, int(n*split), replace = False)\n",
        "    test = [i for i in np.arange(n) if i not in train]\n",
        "    TrainR = R[train,:]\n",
        "    TestR = R[test,:]\n",
        "    TrainY = Ut[train,:]\n",
        "    TestY = Ut[test,:]\n",
        "    D = TrainR.shape[1]\n",
        "\n",
        "    # Set up the initial tolerance and l0 penalty\n",
        "    d_tol = float(d_tol)\n",
        "    tol = d_tol\n",
        "    if l0_penalty == None: l0_penalty = 0.001#*np.linalg.cond(R)\n",
        "\n",
        "    # Get the standard least squares estimator\n",
        "    w = np.zeros((D,1))\n",
        "    w_best = bestu\n",
        "    #print(w_best)\n",
        "    err_best = np.linalg.norm(TestY - TestR.dot(w_best), 2) + l0_penalty*np.count_nonzero(w_best)\n",
        "    tol_best = 0\n",
        "    print(err_best)\n",
        "    print(np.linalg.norm(TestY - TestR.dot(w_best), 2))\n",
        "    #print(np.linalg.cond(R))\n",
        "\n",
        "    # Now increase tolerance until test performance decreases\n",
        "    for iter in range(maxit):\n",
        "\n",
        "        # Get a set of coefficients and error\n",
        "        w = STRidge(R,Ut,lam,STR_iters,tol,normalize = normalize)\n",
        "        err = np.linalg.norm(TestY - TestR.dot(w), 2) + l0_penalty*np.count_nonzero(w)\n",
        "\n",
        "        # Has the accuracy improved?\n",
        "        if err <= err_best:\n",
        "            err_best = err\n",
        "            w_best = w\n",
        "            tol_best = tol\n",
        "            tol = tol + d_tol\n",
        "\n",
        "        else:\n",
        "            tol = max([0,tol - 2*d_tol])\n",
        "            d_tol  = 2*d_tol / (maxit - iter)\n",
        "            tol = tol + d_tol\n",
        "\n",
        "    if print_best_tol: print (\"Optimal tolerance:\", tol_best)\n",
        "\n",
        "    return w_best, err_best\n",
        "\n",
        "\n",
        "\n",
        "def STRidge(X0, y, lam, maxit, tol, normalize = 2, print_results = False):\n",
        "    \"\"\"\n",
        "    Sequential Threshold Ridge Regression algorithm for finding (hopefully) sparse\n",
        "    approximation to X^{-1}y.  The idea is that this may do better with correlated observables.\n",
        "    This assumes y is only one column\n",
        "    \"\"\"\n",
        "\n",
        "    n,d = X0.shape\n",
        "    X = np.zeros((n,d), dtype=np.complex64)\n",
        "    # First normalize data\n",
        "    if normalize != 0:\n",
        "        Mreg = np.zeros((d,1))\n",
        "        for i in range(0,d):\n",
        "            Mreg[i] = 1.0/(np.linalg.norm(X0[:,i],normalize))\n",
        "            X[:,i] = Mreg[i]*X0[:,i]\n",
        "    else: X = X0\n",
        "\n",
        "    # Get the standard ridge esitmate\n",
        "    if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
        "    else: w = np.linalg.lstsq(X,y)[0]\n",
        "    num_relevant = d\n",
        "    biginds = np.where( abs(w) > tol)[0]\n",
        "\n",
        "    # Threshold and continue\n",
        "    for j in range(maxit):\n",
        "\n",
        "        # Figure out which items to cut out\n",
        "        smallinds = np.where( abs(w) < tol)[0]\n",
        "        new_biginds = [i for i in range(d) if i not in smallinds]\n",
        "\n",
        "        # If nothing changes then stop\n",
        "        if num_relevant == len(new_biginds): break\n",
        "        else: num_relevant = len(new_biginds)\n",
        "\n",
        "        # Also make sure we didn't just lose all the coefficients\n",
        "        if len(new_biginds) == 0:\n",
        "            if j == 0:\n",
        "                #if print_results: print \"Tolerance too high - all coefficients set below tolerance\"\n",
        "                return w\n",
        "            else: break\n",
        "        biginds = new_biginds\n",
        "\n",
        "        # Otherwise get a new guess\n",
        "        w[smallinds] = 0\n",
        "        if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
        "        else: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
        "\n",
        "    # Now that we have the sparsity pattern, use standard least squares to get w\n",
        "    if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
        "\n",
        "    if normalize != 0: return np.multiply(Mreg,w)\n",
        "    else: return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUXK61H9Yjfh"
      },
      "outputs": [],
      "source": [
        "from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK\n",
        "import hyperopt\n",
        "import numpy as np\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "from hyperopt.base import miscs_update_idxs_vals\n",
        "from hyperopt.pyll.base import Apply\n",
        "\n",
        "\n",
        "def recursiveFindNodes(root, node_type='switch'):\n",
        "    nodes = []\n",
        "    if isinstance(root, (list, tuple)):\n",
        "        for node in root:\n",
        "            nodes.extend(recursiveFindNodes(node, node_type))\n",
        "    elif isinstance(root, dict):\n",
        "        for node in root.values():\n",
        "            nodes.extend(recursiveFindNodes(node, node_type))\n",
        "    elif isinstance(root, (Apply)):\n",
        "        if root.name == node_type:\n",
        "            nodes.append(root)\n",
        "\n",
        "        for node in root.pos_args:\n",
        "            if node.name == node_type:\n",
        "                nodes.append(node)\n",
        "        for _, node in root.named_args:\n",
        "            if node.name == node_type:\n",
        "                nodes.append(node)\n",
        "    return nodes\n",
        "\n",
        "\n",
        "def parameters(space):\n",
        "    # Analyze the domain instance to find parameters\n",
        "    parameters = {}\n",
        "    if isinstance(space, dict):\n",
        "        space = list(space.values())\n",
        "    for node in recursiveFindNodes(space, 'switch'):\n",
        "\n",
        "        # Find the name of this parameter\n",
        "        paramNode = node.pos_args[0]\n",
        "        assert paramNode.name == 'hyperopt_param'\n",
        "        paramName = paramNode.pos_args[0].obj\n",
        "\n",
        "        # Find all possible choices for this parameter\n",
        "        values = [literal.obj for literal in node.pos_args[1:]]\n",
        "        parameters[paramName] = np.array(range(len(values)))\n",
        "    return parameters\n",
        "\n",
        "\n",
        "def spacesize(space):\n",
        "    # Compute the number of possible combinations\n",
        "    params = parameters(space)\n",
        "    return np.prod([len(values) for values in params.values()])\n",
        "\n",
        "\n",
        "def suggest(new_ids, domain, trials, seed):\n",
        "\n",
        "    # Analyze the domain instance to find parameters\n",
        "    params = parameters(domain.expr)\n",
        "\n",
        "    # Compute all possible combinations\n",
        "    s = [[(name, value) for value in values] for name, values in params.items()]\n",
        "    values = list(itertools.product(*s))\n",
        "\n",
        "    rval = []\n",
        "    for _, new_id in enumerate(new_ids):\n",
        "        # -- sample new specs, idxs, vals\n",
        "        idxs = {name: np.array([new_id]) for name in params.keys()}\n",
        "        vals = {name: np.array([value]) for name, value in values[new_id]}\n",
        "\n",
        "        new_result = domain.new_result()\n",
        "        new_misc = dict(tid=new_id, cmd=domain.cmd, workdir=domain.workdir)\n",
        "        miscs_update_idxs_vals([new_misc], idxs, vals)\n",
        "        rval.extend(trials.new_trial_docs([new_id],\n",
        "                                          [None], [new_result], [new_misc]))\n",
        "    return rval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrosNS11fC5y",
        "outputId": "cf96c98b-6e20-4bdc-cc6f-e90a1cfb4364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7351113599767192\n",
            "1.7311113599767192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-2cf3ee62811d>:79: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
            "<ipython-input-18-2cf3ee62811d>:109: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
            "<ipython-input-18-2cf3ee62811d>:109: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
            "<ipython-input-18-2cf3ee62811d>:105: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0631408164124971\n",
            "1.0591408164124971\n"
          ]
        }
      ],
      "source": [
        "ucoef=TrainSTRidge(linear_matuf1,uut,coefuspy,50, 10)\n",
        "vcoef=TrainSTRidge(linear_matvf1,uvt,coefvspy,50, 10)\n",
        "\n",
        "#record terms and coe with sparsity\n",
        "\n",
        "finalindu=list(np.where(ucoef[0]!=0)[0])\n",
        "fl1=[]\n",
        "fcoeu=[]\n",
        "\n",
        "for i in finalindu:\n",
        "  fl1.append(luspy[i])\n",
        "\n",
        "  fcoeu.append(ucoef[0][i].real)\n",
        "\n",
        "\n",
        "\n",
        "finalindv=list(np.where(vcoef[0]!=0)[0])\n",
        "fl2=[]\n",
        "fcoev=[]\n",
        "\n",
        "for i in finalindv:\n",
        "\n",
        "  fl2.append(lvspy[i])\n",
        "\n",
        "  fcoev.append(vcoef[0][i].real)\n",
        "\n",
        "termusp1c={}\n",
        "termvsp1c={}\n",
        "\n",
        "for order, ele in enumerate(fl1):\n",
        "  if \"/\" not in str(ele):\n",
        "    termusp1c[ele]=1\n",
        "\n",
        "for order, ele in enumerate(fl2):\n",
        "  if \"/\" not in str(ele):\n",
        "    termvsp1c[ele]=1\n",
        "\n",
        "if len(termusp)==0:\n",
        "  termusp={i:[0]*simulation for i in fl1}\n",
        "  termvsp={i:[0]*simulation for i in fl2}\n",
        "  for order, ele in enumerate(fl1):\n",
        "\n",
        "    termusp[ele][sim]=round(fcoeu[order][0],5)\n",
        "  for order, ele in enumerate(fl2):\n",
        "\n",
        "    termvsp[ele][sim]=round(fcoev[order][0],5)\n",
        "  termuspc.update(termusp1c)\n",
        "  termvspc.update(termvsp1c)\n",
        "else:\n",
        "\n",
        "  for order, ele in enumerate(fl1):\n",
        "    if ele in list(termusp.keys()):\n",
        "\n",
        "        termusp[ele][sim]=round(fcoeu[order][0],5)\n",
        "    else:\n",
        "      termusp[ele]=[0]*simulation\n",
        "\n",
        "      termusp[ele][sim]=round(fcoeu[order][0],5)\n",
        "\n",
        "\n",
        "\n",
        "  for order, ele in enumerate(fl2):\n",
        "    if ele in list(termvsp.keys()):\n",
        "\n",
        "      termvsp[ele][sim]=round(fcoev[order][0],5)\n",
        "    else:\n",
        "      termvsp[ele]=[0]*simulation\n",
        "\n",
        "      termvsp[ele][sim]=round(fcoev[order][0],5)\n",
        "\n",
        "  for order, item in enumerate(termusp1c):\n",
        "    if item in list(termuspc.keys()):\n",
        "      termuspc[item]+=termusp1c[item]\n",
        "\n",
        "    else:\n",
        "      termuspc[item]=termusp1c[item]\n",
        "\n",
        "  for order, item in enumerate(termvsp1c):\n",
        "    if item in list(termvspc.keys()):\n",
        "      termvspc[item]+=termvsp1c[item]\n",
        "\n",
        "    else:\n",
        "      termvspc[item]=termvsp1c[item]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrPl0YoTfMEi",
        "outputId": "9aa8396a-dcf2-4d97-aabf-a16995b165fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: [0.98607],\n",
              " u00: [-0.97668],\n",
              " u00*v00/(1.0*u00**2 + 0.25488950789362*u00 + 0.257304836935724): [-0.50694],\n",
              " u02 + u20: [0.29514]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "termusp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb9aXvh2Wu5N",
        "outputId": "53fcdc96-8ce6-48a7-e5a2-23636334102c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{u00*v00/(1.0*u00**2 + 0.252608602212288*u00 + 0.266239556147262): [-0.52067],\n",
              " 1: [0.40089],\n",
              " v02 + v20: [0.39174],\n",
              " v00: [-0.1958]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "termvsp"
      ]
    }
  ]
}