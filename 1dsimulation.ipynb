{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NIKEK9tYwlr",
        "outputId": "bf4f25d5-f90f-45dd-b958-1975de045562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: timeout_decorator in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/mPDE-Net/')\n",
        "sys.path.append('/content/drive/MyDrive/mPDE-Net/aTEAM/')\n",
        "!pip install timeout_decorator\n",
        "!pip install -U PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KGzVMaVglzq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cc74fc-cdbd-4d71-82fa-864b9daf193a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-02784bb70f40>:175: DeprecationWarning: Please use `sqrt` from the `scipy.optimize` namespace, the `scipy.optimize.optimize` namespace is deprecated.\n",
            "  from scipy.optimize.optimize import sqrt\n",
            "<ipython-input-9-02784bb70f40>:180: DeprecationWarning: Please use `sqrt` from the `scipy.optimize` namespace, the `scipy.optimize.optimize` namespace is deprecated.\n",
            "  from scipy.optimize.optimize import sqrt\n"
          ]
        }
      ],
      "source": [
        "from sympy.parsing.sympy_parser import parse_expr\n",
        "from sympy import symbols, lambdify\n",
        "def givevals(dic, setexp,bs):\n",
        "  u00=\"u0\"\n",
        "  v00=\"v0\"\n",
        "  lnu=\"lnu\"\n",
        "  I=\"I\"\n",
        "\n",
        "  newlist={}\n",
        "  for expr in list(setexp.keys()):\n",
        "\n",
        "\n",
        "    if expr == 1:\n",
        "        newlist[expr]=np.ones((200*bs,1))\n",
        "    elif u00 in str(expr) and v00 in str(expr):\n",
        "\n",
        "      f = lambdify({u00,v00}, expr)\n",
        "      finalf=f(dic[u00][:,0],dic[v00][:,0])\n",
        "      newlist[expr]=finalf.reshape((200*bs,1))\n",
        "    elif u00 in str(expr) and v00 not in str(expr):\n",
        "\n",
        "      f = lambdify(u00, expr)\n",
        "      finalf=f(dic[u00][:,0])\n",
        "      newlist[expr]=finalf.reshape((200*bs,1))\n",
        "    elif u00 not in str(expr) and v00 in str(expr):\n",
        "      f = lambdify(v00, expr)\n",
        "      finalf=f(dic[v00][:,0])\n",
        "      newlist[expr]=finalf.reshape((200*bs,1))\n",
        "\n",
        "    elif \"exp\"  in str(expr) and \"I\" not in str(expr):\n",
        "\n",
        "      f = lambdify(lnu, expr)\n",
        "      finalf=f(dic[lnu][:,0])\n",
        "\n",
        "      newlist[expr]=finalf.reshape((200*bs,1))\n",
        "    elif \"exp\"  in str(expr) and \"I\" in str(expr):\n",
        "\n",
        "      f = lambdify((lnu,I), expr)\n",
        "      finalf=f(dic[lnu][:,0],dic[I][:,0])\n",
        "      newlist[expr]=finalf.reshape((200*bs,1))\n",
        "\n",
        "    else:\n",
        "      for i in list(dic.keys()):\n",
        "        if str(i) == str(expr):\n",
        "          newlist[expr]=dic[i]\n",
        "  return newlist\n",
        "\n",
        "def TrainSTRidge(R, Ut, bestu,lam, d_tol, maxit = 35, STR_iters = 30, l0_penalty = None, normalize = 2, split = 0.8, print_best_tol = False):\n",
        "    \"\"\"\n",
        "    This function trains a predictor using STRidge.\n",
        "    It runs over different values of tolerance and trains predictors on a training set, then evaluates them\n",
        "    using a loss function on a holdout set.\n",
        "    Please note published article has typo.  Loss function used here for model selection evaluates fidelity using 2-norm,\n",
        "    not squared 2-norm.\n",
        "    \"\"\"\n",
        "\n",
        "    # Split data into 80% training and 20% test, then search for the best tolderance.\n",
        "    np.random.seed(0) # for consistancy\n",
        "    n,_ = R.shape\n",
        "    train = np.random.choice(n, int(n*split), replace = False)\n",
        "    test = [i for i in np.arange(n) if i not in train]\n",
        "    TrainR = R[train,:]\n",
        "    TestR = R[test,:]\n",
        "    TrainY = Ut[train,:]\n",
        "    TestY = Ut[test,:]\n",
        "    D = TrainR.shape[1]\n",
        "\n",
        "    # Set up the initial tolerance and l0 penalty\n",
        "    d_tol = float(d_tol)\n",
        "    tol = d_tol\n",
        "    if l0_penalty == None: l0_penalty = 0.1#*np.linalg.cond(R)\n",
        "\n",
        "    # Get the standard least squares estimator\n",
        "    w = np.zeros((D,1))\n",
        "    w_best = bestu\n",
        "    print(w_best)\n",
        "    err_best = np.linalg.norm(TestY - TestR.dot(w_best), 2) + l0_penalty*np.count_nonzero(w_best)\n",
        "    tol_best = 0\n",
        "    print(err_best)\n",
        "    print(np.linalg.norm(TestY - TestR.dot(w_best), 2))\n",
        "    #print(np.linalg.cond(R))\n",
        "\n",
        "    # Now increase tolerance until test performance decreases\n",
        "    for iter in range(maxit):\n",
        "\n",
        "        # Get a set of coefficients and error\n",
        "        w = STRidge(R,Ut,lam,STR_iters,tol,normalize = normalize)\n",
        "        err = np.linalg.norm(TestY - TestR.dot(w), 2) + l0_penalty*np.count_nonzero(w)\n",
        "\n",
        "        # Has the accuracy improved?\n",
        "        if err <= err_best:\n",
        "            err_best = err\n",
        "            w_best = w\n",
        "            tol_best = tol\n",
        "            tol = tol + d_tol\n",
        "\n",
        "        else:\n",
        "            tol = max([0,tol - 2*d_tol])\n",
        "            d_tol  = 2*d_tol / (maxit - iter)\n",
        "            tol = tol + d_tol\n",
        "\n",
        "    if print_best_tol: print (\"Optimal tolerance:\", tol_best)\n",
        "\n",
        "    return w_best, err_best\n",
        "\n",
        "\n",
        "\n",
        "def STRidge(X0, y, lam, maxit, tol, normalize = 2, print_results = False):\n",
        "    \"\"\"\n",
        "    Sequential Threshold Ridge Regression algorithm for finding (hopefully) sparse\n",
        "    approximation to X^{-1}y.  The idea is that this may do better with correlated observables.\n",
        "    This assumes y is only one column\n",
        "    \"\"\"\n",
        "\n",
        "    n,d = X0.shape\n",
        "    X = np.zeros((n,d), dtype=np.complex64)\n",
        "    # First normalize data\n",
        "    if normalize != 0:\n",
        "        Mreg = np.zeros((d,1))\n",
        "        for i in range(0,d):\n",
        "            Mreg[i] = 1.0/(np.linalg.norm(X0[:,i],normalize))\n",
        "            X[:,i] = Mreg[i]*X0[:,i]\n",
        "    else: X = X0\n",
        "\n",
        "    # Get the standard ridge esitmate\n",
        "    if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n",
        "    else: w = np.linalg.lstsq(X,y)[0]\n",
        "    num_relevant = d\n",
        "    biginds = np.where( abs(w) > tol)[0]\n",
        "\n",
        "    # Threshold and continue\n",
        "    for j in range(maxit):\n",
        "\n",
        "        # Figure out which items to cut out\n",
        "        smallinds = np.where( abs(w) < tol)[0]\n",
        "        new_biginds = [i for i in range(d) if i not in smallinds]\n",
        "\n",
        "        # If nothing changes then stop\n",
        "        if num_relevant == len(new_biginds): break\n",
        "        else: num_relevant = len(new_biginds)\n",
        "\n",
        "        # Also make sure we didn't just lose all the coefficients\n",
        "        if len(new_biginds) == 0:\n",
        "            if j == 0:\n",
        "                #if print_results: print \"Tolerance too high - all coefficients set below tolerance\"\n",
        "                return w\n",
        "            else: break\n",
        "        biginds = new_biginds\n",
        "\n",
        "        # Otherwise get a new guess\n",
        "        w[smallinds] = 0\n",
        "        if lam != 0: w[biginds] = np.linalg.lstsq(X[:, biginds].T.dot(X[:, biginds]) + lam*np.eye(len(biginds)),X[:, biginds].T.dot(y))[0]\n",
        "        else: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
        "\n",
        "    # Now that we have the sparsity pattern, use standard least squares to get w\n",
        "    if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
        "\n",
        "    if normalize != 0: return np.multiply(Mreg,w)\n",
        "    else: return w\n",
        "\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval, STATUS_FAIL\n",
        "from hyperopt.pyll.base import scope\n",
        "import numpy as np\n",
        "space={\"sp\": hp.loguniform('sp', np.log(1e-7), np.log(1e-4)),\n",
        "       \"msp\": hp.loguniform('msp', np.log(1e-7), np.log(1e-4)),\n",
        "       \"stab\": hp.loguniform('stab', np.log(1e-7), np.log(1e-4)),\n",
        "       # \"sp0\": hp.loguniform('sp0', np.log(0.000000001), np.log(0.000001)),\n",
        "       # #\"msp0\": hp.loguniform('msp0', np.log(0.000000001), np.log(0.0001)),\n",
        "       # \"stab0\": hp.loguniform('stab0', np.log(0.000000001), np.log(0.000001)),\n",
        "       }\n",
        "\n",
        "\n",
        "##insert data\n",
        "from scipy.optimize.optimize import sqrt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from numpy import linalg as LA\n",
        "from scipy.optimize.optimize import sqrt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from numpy import linalg as LA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "46fETJaAmqrU"
      },
      "outputs": [],
      "source": [
        "datav=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/Ca00510-1.csv\",  index_col=0)\n",
        "datav1=datav.values[0:,:]\n",
        "datau=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/R00510-1.csv\",  index_col=0)\n",
        "datau1=datau.values[0:,:]\n",
        "\n",
        "\n",
        "datav2=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int1Ca000110.csv\",  index_col=0)\n",
        "datav2=datav2.values[0:,:]\n",
        "datau2=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int1R0000110.csv\",  index_col=0)\n",
        "datau2=datau2.values[0:,:]\n",
        "\n",
        "datav3=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int2Ca000110.csv\",  index_col=0)\n",
        "datav3=datav3.values[0:,:]\n",
        "datau3=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int2R0000110.csv\",  index_col=0)\n",
        "datau3=datau3.values[0:,:]\n",
        "\n",
        "\n",
        "datav4=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int3Ca000110.csv\",  index_col=0)\n",
        "datav4=datav4.values[0:,:]\n",
        "datau4=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int3R0000110.csv\",  index_col=0)\n",
        "datau4=datau4.values[0:,:]\n",
        "\n",
        "\n",
        "datav5=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int6Ca000110.csv\",  index_col=0)\n",
        "datav5=datav5.values[0:,:]\n",
        "datau5=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/int6R0000110.csv\",  index_col=0)\n",
        "datau5=datau5.values[0:,:]\n",
        "\n",
        "\n",
        "\n",
        "datavt=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/testint1Ca00510.csv\",  index_col=0)\n",
        "datavt=datavt.values[0:,:]\n",
        "dataut=pd.read_csv(\"/content/drive/MyDrive/mPDE-Net/data/testint1R00510.csv\",  index_col=0)\n",
        "dataut=dataut.values[0:,:]\n",
        "\n",
        "\n",
        "s=3\n",
        "datav1=datav1[:,::s]\n",
        "datau1=datau1[:,::s]\n",
        "\n",
        "datav2=datav2[:,::s]\n",
        "datau2=datau2[:,::s]\n",
        "\n",
        "datav3=datav3[:,::s]\n",
        "datau3=datau3[:,::s]\n",
        "datav4=datav4[:,::s]\n",
        "datau4=datau4[:,::s]\n",
        "\n",
        "datav5=datav5[:,::s]\n",
        "datau5=datau5[:,::s]\n",
        "\n",
        "\n",
        "datavt=datavt[:,::s]\n",
        "dataut=dataut[:,::s]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convdata(datau,datav, bs,head,tail,datausize, datavsize):\n",
        "\n",
        "\n",
        "\n",
        "  if tail==0 and head != 0:\n",
        "    datau=datau[:head]\n",
        "    datav=datav[:head]\n",
        "  elif head==0 and tail !=0:\n",
        "    datau=datau[tail:]\n",
        "    datav=datav[tail:]\n",
        "  elif tail !=0 and head !=0:\n",
        "    datau=datau[head:tail]\n",
        "    datav=datav[head:tail]\n",
        "  else:\n",
        "    datau=datau\n",
        "    datav=datav\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  lentime=datau.shape[0]\n",
        "  lenx=datau.shape[1]\n",
        "  u=[]\n",
        "\n",
        "  for i in range(0,16):\n",
        "\n",
        "    u1=datau[i,:]\n",
        "    v1=datav[i,:]\n",
        "    u1=torch.from_numpy(u1).to(dtype=torch.float64, device=\"cuda\")\n",
        "    v1=torch.from_numpy(v1).to(dtype=torch.float64, device=\"cuda\")\n",
        "    arr=[]\n",
        "    arr.append(u1)\n",
        "    arr.append(v1)\n",
        "\n",
        "    if bs !=1:\n",
        "      for j in range(bs*2,lentime):\n",
        "        if j%(bs*2)==1:\n",
        "          u1=datau[i+j,:]\n",
        "          v1=datav[i+j,:]\n",
        "          u1=torch.from_numpy(u1).to(dtype=torch.float64, device=\"cuda\")\n",
        "          v1=torch.from_numpy(v1).to(dtype=torch.float64, device=\"cuda\")\n",
        "          arr.append(u1)\n",
        "          arr.append(v1)\n",
        "    arr=torch.stack(arr, dim=0)\n",
        "\n",
        "    arr = arr.view([bs, 2]+[datau.shape[-1]])\n",
        "    u.append(arr)\n",
        "  return u\n",
        "\n",
        "\n",
        "\n",
        "data1=convdata(datau1,datav1,10,0,0,0,0)\n",
        "data2=convdata(datau2,datav2,1,0,0,0,0)\n",
        "data3=convdata(datau3,datav3,1,0,0,0,0)\n",
        "data4=convdata(datau4,datav4,1,0,0,0,0)\n",
        "data5=convdata(datau5,datav5,1,0,0,0,0)\n",
        "\n",
        "\n",
        "\n",
        "data=[]\n",
        "for j in range(len(data3)):\n",
        "  #a=data3[j]\n",
        "  a=torch.cat((data1[j], data2[j]))\n",
        "  c=torch.cat((a, data3[j]))\n",
        "  d=torch.cat((c, data4[j]))\n",
        "  e=torch.cat((d, data5[j]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  data.append(e)\n",
        "\n",
        "datan=data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "datatest=convdata(dataut,datavt,10,0,0,0,0)\n",
        "datat=[]\n",
        "\n",
        "for j in range(len(data1)):\n",
        "  a=datatest[j][:4]\n",
        "\n",
        "\n",
        "\n",
        "  datat.append(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byL4sESk8xn6",
        "outputId": "88ff712c-9b9e-4c43-f7c3-4a6749e8e402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-94cab508e8dd>:6: DeprecationWarning: Please use `fmin_l_bfgs_b` from the `scipy.optimize` namespace, the `scipy.optimize.lbfgsb` namespace is deprecated.\n",
            "  from scipy.optimize.lbfgsb import fmin_l_bfgs_b as lbfgsb\n",
            "<ipython-input-4-94cab508e8dd>:7: DeprecationWarning: Please use `fmin_slsqp` from the `scipy.optimize` namespace, the `scipy.optimize.slsqp` namespace is deprecated.\n",
            "  from scipy.optimize.slsqp import fmin_slsqp as slsqp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brusselator\n",
            "self._dx [0.07853981633974483, 0.07853981633974483]\n",
            "_FDNd kernel_size [1, 19]\n",
            "self._dx [0.07853981633974483, 0.07853981633974483]\n",
            "_FDNd kernel_size [1, 19]\n",
            "self._dx [0.07853981633974483, 0.07853981633974483]\n",
            "_FDNd kernel_size [1, 19]\n",
            "ranum 62301115\n",
            "torranum 53123836\n",
            "max_dt 1e-07\n",
            "last layer\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(3.7618, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.001661\n",
            "         Iterations: 368\n",
            "         Function evaluations: 408\n",
            "         Gradient evaluations: 408\n",
            "convolution moment and kernels\n",
            "Moment [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[ 1.80e-17 -2.62e-16  1.85e-15 -8.55e-15  2.98e-14 -8.34e-14  1.91e-13 -3.55e-13\n",
            "   5.37e-13  1.00e+00  6.35e-13 -4.93e-13  3.03e-13 -1.46e-13  5.36e-14 -1.45e-14\n",
            "   2.73e-15 -3.18e-16  1.72e-17]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[ 5.08e-07 -1.16e-05  1.28e-04 -9.32e-04  5.03e-03 -2.20e-02  8.48e-02 -3.27e-01\n",
            "   1.80e+00 -3.08e+00  1.80e+00 -3.27e-01  8.48e-02 -2.20e-02  5.03e-03 -9.32e-04\n",
            "   1.28e-04 -1.16e-05  5.08e-07]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.5 0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.5 0.  0.  0.  0.  0.  0.  0.  1.  0. ]]\n",
            "SymNet parameters\n",
            "[0.5 0.5]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -1.72  0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.03  0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.95 0.03]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0.88 0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[0.01 0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.01 0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.07 0.   0.   0.1  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.07]\n",
            " [0.07 0.   0.   0.06 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.06]]\n",
            "SymNet parameters\n",
            "[0.04 0.06]\n",
            "SymNet parameters\n",
            "[[0.46 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.37 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.23 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.32 0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.07 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-2.51e+00  0.00e+00  2.67e-02  4.28e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  6.62e-03  0.00e+00\n",
            "   6.75e-01  0.00e+00  3.02e+00 -7.94e+00]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.5 0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.5 0.  0.  0.  0.  0.  0.  0.  1.  0. ]]\n",
            "SymNet parameters\n",
            "[0.5 0.5]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.5 0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.5 0.  0.  0.  0.  0.  1.  0. ]]\n",
            "SymNet parameters\n",
            "[0.5 0.5]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0.04 0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.01 0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.04 0.   0.   0.04 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.01]\n",
            " [0.03 0.   0.   0.07 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.07]]\n",
            "SymNet parameters\n",
            "[0.07 0.1 ]\n",
            "SymNet parameters\n",
            "[[0.44 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.23 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.22 0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.23 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.12]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.83  0.    0.   -0.33  0.    0.04  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(3.7795, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.000330\n",
            "         Iterations: 209\n",
            "         Function evaluations: 240\n",
            "         Gradient evaluations: 228\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.00e+00  0.00e+00  7.09e-01 -2.09e-03 -8.60e-03  6.29e-04 -1.49e-02  1.61e-03\n",
            "   3.30e-02 -3.01e-03 -6.52e-02  2.43e-03  7.92e-02 -5.47e-04 -5.56e-03 -4.10e-04\n",
            "  -8.12e-02  5.04e-04 -5.85e-02]]\n",
            "keneral [[-0.01  0.12 -0.63  1.77 -2.75  1.82  0.89 -1.98  0.35  2.08 -0.36 -1.3   0.75  1.57\n",
            "  -2.48  1.64 -0.6   0.12 -0.01]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  2.66e+00 -4.38e-02  2.31e+00 -4.80e-02\n",
            "   2.54e-01  5.07e-04 -9.95e-01  2.62e-02 -9.33e-01  1.96e-02 -4.70e-01  7.89e-03\n",
            "  -1.63e-01  2.13e-03 -4.28e-02]]\n",
            "keneral [[-0.   -0.    0.01  0.01  0.01  0.   -0.   -0.01 -0.01 -0.03 -0.01 -0.01 -0.    0.\n",
            "   0.01  0.01  0.01 -0.   -0.  ]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.33 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.33 0.   0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.33 0.33]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -1.58  0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.15  0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.82 0.04]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0.32 0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[0.08 0.   0.   0.08 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.08 0.   0.   0.08 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.09 0.09]\n",
            "SymNet parameters\n",
            "[[-0.09  0.    0.   -0.07  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.09]\n",
            " [-0.08  0.    0.   -0.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.08]]\n",
            "SymNet parameters\n",
            "[ 0.08 -0.08]\n",
            "SymNet parameters\n",
            "[[0.48 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.66 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.06 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15 0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.09 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-2.62  0.    0.15 -0.15  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.09  0.    0.59  0.    3.62 -7.77]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.33 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.33 0.   0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.33 0.33]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.33 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.33 0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.33 0.33]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0.08 0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[0.08 0.   0.   0.08 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.08 0.   0.   0.08 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.08  0.    0.    0.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.08]\n",
            " [ 0.08  0.    0.   -0.09  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.09]]\n",
            "SymNet parameters\n",
            "[-0.09 -0.07]\n",
            "SymNet parameters\n",
            "[[ 0.27  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.07  0.    0.\n",
            "   0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.06 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.05 0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.06 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.12]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.97  0.    0.   -0.41  0.    9.01  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.000505\n",
            "         Iterations: 137\n",
            "         Function evaluations: 160\n",
            "         Gradient evaluations: 148\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.    0.    0.88 -0.03  0.02  0.04 -0.06 -0.05  0.05  0.05 -0.02 -0.03 -0.02 -0.02\n",
            "   0.02  0.03  0.02  0.03  0.01]]\n",
            "keneral [[-0.    0.03 -0.15  0.38 -0.48  0.06  0.43  0.11 -0.46  0.83  0.05  0.37 -0.29 -0.06\n",
            "   0.42 -0.41  0.19 -0.04  0.  ]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.    0.    1.    0.    3.38 -0.03  3.85 -0.05  1.08 -0.02 -1.55  0.02 -1.96  0.03\n",
            "  -1.18  0.02 -0.47  0.01 -0.14]]\n",
            "keneral [[-0.    0.01  0.01  0.01  0.    0.   -0.   -0.01 -0.01 -0.02 -0.01 -0.   -0.    0.\n",
            "   0.    0.01  0.01  0.01 -0.  ]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.17 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.17 0.   0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.17 0.17]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -1.49  0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.01  0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.64 0.03]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0.15 0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-0.08  0.    0.   -0.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [-0.08  0.    0.   -0.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.12 -0.12]\n",
            "SymNet parameters\n",
            "[[0.07 0.   0.   0.09 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.07]\n",
            " [0.07 0.   0.   0.08 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.08]]\n",
            "SymNet parameters\n",
            "[-0.07  0.08]\n",
            "SymNet parameters\n",
            "[[0.52 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.61 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -0.1   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.01  0.    0.    0.\n",
            "   0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.08 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-2.83  0.    0.1   0.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.13  0.    0.56  0.    3.35 -7.61]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.17 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.17 0.   0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.17 0.17]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.17 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.17 0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[0.17 0.17]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-0.08  0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-0.08  0.    0.   -0.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [-0.08  0.    0.   -0.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-0.08  0.    0.   -0.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.08]\n",
            " [-0.08  0.    0.    0.07  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.07]]\n",
            "SymNet parameters\n",
            "[0.07 0.09]\n",
            "SymNet parameters\n",
            "[[0.11 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.09 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -0.1   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.08  0.    0.    0.\n",
            "   0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.   -0.1   0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.12]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.97  0.    0.   -0.41  0.    9.35  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.000684\n",
            "         Iterations: 569\n",
            "         Function evaluations: 615\n",
            "         Gradient evaluations: 603\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.    0.    4.66 -0.15  0.72  0.32 -0.82 -0.28  0.54  0.06 -0.04  0.21 -0.28 -0.11\n",
            "   0.07 -0.23  0.18 -0.14  0.11]]\n",
            "keneral [[ 0.02 -0.18  0.6  -0.81 -0.09  0.87  0.44 -0.14 -0.84  0.81 -0.27  0.12  0.19  0.38\n",
            "   0.14 -0.45  0.25 -0.06  0.  ]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.    0.    1.    0.    4.03 -0.05  6.44 -0.15  5.45 -0.21  2.69 -0.17  0.75 -0.09\n",
            "   0.05 -0.03 -0.05 -0.01 -0.03]]\n",
            "keneral [[-0.    0.01  0.01  0.01  0.    0.   -0.   -0.   -0.01 -0.02 -0.01 -0.   -0.    0.\n",
            "   0.    0.01  0.01  0.01 -0.  ]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-0.02  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.13  0.    0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.16  0.02]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    2.06  0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.   -0.01  0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.22 0.01]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-0.03  0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 0.08  0.    0.   -0.02  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [-0.01  0.    0.   -0.06  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.08 -0.  ]\n",
            "SymNet parameters\n",
            "[[-0.17  0.    0.    0.13  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.08]\n",
            " [ 0.01  0.    0.   -0.06  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.19]]\n",
            "SymNet parameters\n",
            "[0.07 0.01]\n",
            "SymNet parameters\n",
            "[[0.75 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.28 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.09 0.   0.   0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.74e+00  0.00e+00  9.98e-02  2.06e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.48e-02  0.00e+00\n",
            "   5.27e-01  0.00e+00  3.58e+00 -2.24e+00]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.15 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.05 0.   0.   0.   0.   0.   0.   0.   1.   0.  ]]\n",
            "SymNet parameters\n",
            "[-0.04  0.06]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -0.04  0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.   -0.04  0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[-0.01 -0.04]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 0.01  0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.1   0.    0.   -0.05  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-0.06  0.    0.   -0.02  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.02]\n",
            " [ 0.03  0.    0.    0.02  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.13]]\n",
            "SymNet parameters\n",
            "[0.01 0.05]\n",
            "SymNet parameters\n",
            "[[ 0.22  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.02  0.    0.\n",
            "   0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.03  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -0.01  0.    0.    0.\n",
            "   0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.    0.    0.    0.   -0.12  0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.12]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.98  0.    0.   -0.41  0.    9.37  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.000845\n",
            "         Iterations: 1000\n",
            "         Function evaluations: 1083\n",
            "         Gradient evaluations: 1083\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.    0.    3.42  0.07  1.27  0.02 -0.92 -0.03  0.24  0.03  0.36 -0.01 -0.21 -0.01\n",
            "  -0.32  0.01 -0.16  0.01 -0.05]]\n",
            "keneral [[-2.21e-03  5.36e-03  3.20e-02 -1.01e-01 -6.77e-02  2.95e-01  3.59e-01 -5.14e-02\n",
            "  -6.60e-01  1.22e+00 -2.97e-01 -1.27e-01  6.16e-02  3.88e-01  1.98e-01 -3.87e-01\n",
            "   1.60e-01 -2.27e-02  2.98e-04]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  4.42e+00 -1.94e-02  8.04e+00 -4.76e-02\n",
            "   8.16e+00 -4.85e-02  5.33e+00 -2.77e-02  2.43e+00 -9.88e-03  8.22e-01 -2.19e-03\n",
            "   2.14e-01 -2.33e-04  4.42e-02]]\n",
            "keneral [[ 5.57e-05  6.72e-03  7.06e-03  5.20e-03  2.81e-03  5.92e-05 -1.96e-03 -3.92e-03\n",
            "  -6.03e-03 -1.99e-02 -5.54e-03 -4.29e-03 -2.51e-03  1.53e-07  3.13e-03  5.41e-03\n",
            "   7.25e-03  6.41e-03  8.92e-05]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 5.09e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-2.54e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-0.   -0.01]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -0.02  0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.   -0.    0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.33 0.02]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-0.17  0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-0.  0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "SymNet parameters\n",
            "[ 0.01 -0.  ]\n",
            "SymNet parameters\n",
            "[[-0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.  ]\n",
            " [ 0.02  0.    0.   -0.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.51 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.93 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  4.85e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00 -2.59e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.56e+00  0.00e+00  1.05e-01  4.39e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.16e-02  0.00e+00\n",
            "   4.45e-01  0.00e+00  3.53e+00 -4.99e-01]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-2.29e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-2.46e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 4.06e-04 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 1.31e-02 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-2.02e-04  0.00e+00  0.00e+00 -1.27e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.54e-03  0.00e+00  0.00e+00  8.34e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-0.    0.    0.   -0.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "  -0.  ]\n",
            " [ 0.01  0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.  ]]\n",
            "SymNet parameters\n",
            "[ 0. -0.]\n",
            "SymNet parameters\n",
            "[[-0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.  0.  0.  0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.12]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.98  0.    0.   -0.41  0.    9.51  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.001049\n",
            "         Iterations: 430\n",
            "         Function evaluations: 479\n",
            "         Gradient evaluations: 467\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.    0.    3.59  0.02  1.25  0.06 -0.86 -0.07  0.19  0.03  0.37  0.02 -0.18 -0.03\n",
            "  -0.33 -0.03 -0.2  -0.01 -0.07]]\n",
            "keneral [[-0.    0.01  0.   -0.03 -0.11  0.22  0.47  0.02 -0.66  0.96 -0.25 -0.    0.17  0.25\n",
            "   0.11 -0.19  0.04  0.01 -0.  ]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  4.51e+00  9.04e-04  8.37e+00 -1.65e-02\n",
            "   8.66e+00 -4.69e-02  5.77e+00 -5.58e-02  2.70e+00 -3.90e-02  9.34e-01 -1.83e-02\n",
            "   2.50e-01 -6.27e-03  5.36e-02]]\n",
            "keneral [[ 3.48e-04  6.54e-03  7.10e-03  5.24e-03  2.54e-03 -1.93e-04 -2.37e-03 -3.88e-03\n",
            "  -5.85e-03 -1.93e-02 -5.38e-03 -3.90e-03 -2.47e-03  2.41e-06  2.51e-03  4.90e-03\n",
            "   6.91e-03  7.08e-03  1.43e-04]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 1.51e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-9.31e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-0.  0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -2.05e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -7.22e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0.58 0.02]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-0.  0.]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-3.90e-04  0.00e+00  0.00e+00 -4.92e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-5.35e-04  0.00e+00  0.00e+00  6.77e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[3.15e-05 1.41e-05]\n",
            "SymNet parameters\n",
            "[[-3.30e-06  0.00e+00  0.00e+00  2.22e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.37e-06]\n",
            " [ 4.03e-05  0.00e+00  0.00e+00  9.66e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.16e-05]]\n",
            "SymNet parameters\n",
            "[ 1.56e-05 -1.22e-03]\n",
            "SymNet parameters\n",
            "[[0.52 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.43 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 1.44e-06 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 7.79e-05 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.64 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.33e+00  0.00e+00  9.89e-02 -7.31e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -9.78e-04  0.00e+00\n",
            "   5.47e-01  0.00e+00  3.39e+00 -8.32e-01]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-6.79e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 1.60e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 1.20e-05 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 5.89e-04 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[1.17e-05 1.83e-04]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[1.96e-05 0.00e+00]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-6.00e-06  0.00e+00  0.00e+00 -3.75e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-8.94e-04  0.00e+00  0.00e+00  2.47e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-5.72e-06  0.00e+00  0.00e+00  1.10e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.37e-05]\n",
            " [ 9.81e-03  0.00e+00  0.00e+00 -3.28e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.21e-06]]\n",
            "SymNet parameters\n",
            "[-1.80e-04 -5.61e-05]\n",
            "SymNet parameters\n",
            "[[4.68e-05 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 1.10e-05 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 1.70e-05 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 1.63e-04 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.21e-05 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  1.15e-01]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.97  0.    0.   -0.41  0.    9.48  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.001254\n",
            "         Iterations: 273\n",
            "         Function evaluations: 317\n",
            "         Gradient evaluations: 305\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.    0.    3.64  0.02  1.32  0.06 -0.94 -0.07  0.29  0.02  0.32  0.04 -0.23 -0.03\n",
            "  -0.27 -0.05 -0.12 -0.03 -0.03]]\n",
            "keneral [[ 2.25e-03 -3.54e-02  1.78e-01 -3.37e-01  3.81e-02  4.37e-01  2.69e-01 -1.26e-01\n",
            "  -6.50e-01  1.32e+00 -4.29e-01 -1.26e-01  1.29e-01  4.28e-01  9.69e-02 -3.13e-01\n",
            "   1.32e-01 -1.72e-02 -1.70e-04]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  4.60e+00 -8.63e-03  8.70e+00 -2.57e-02\n",
            "   9.19e+00 -3.54e-02  6.26e+00 -2.98e-02  3.00e+00 -1.71e-02  1.07e+00 -7.13e-03\n",
            "   2.95e-01 -2.26e-03  6.51e-02]]\n",
            "keneral [[ 5.10e-04  6.88e-03  6.88e-03  4.72e-03  2.27e-03 -1.79e-04 -2.50e-03 -3.79e-03\n",
            "  -5.39e-03 -1.88e-02 -5.20e-03 -3.95e-03 -2.83e-03  1.19e-05  2.40e-03  4.72e-03\n",
            "   6.82e-03  6.97e-03  4.50e-04]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-7.88e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-1.41e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[ 1.67e-05 -1.79e-05]\n",
            "SymNet parameters\n",
            "[[ 0.    0.    0.   -0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
            " [ 0.    0.    0.    0.01  0.    0.    0.    0.    0.    1.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.47 0.02]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-0.04  0.  ]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 3.61e-05  0.00e+00  0.00e+00 -5.14e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 3.96e-05  0.00e+00  0.00e+00 -5.04e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-4.34e-05 -8.07e-05]\n",
            "SymNet parameters\n",
            "[[ 1.73e-07  0.00e+00  0.00e+00  6.16e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -3.85e-07]\n",
            " [-2.10e-06  0.00e+00  0.00e+00 -5.05e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.06e-07]]\n",
            "SymNet parameters\n",
            "[-8.13e-07 -2.53e-02]\n",
            "SymNet parameters\n",
            "[[0.52 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.62 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -7.51e-08  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00 -4.07e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.8  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.42  0.    0.1  -0.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.01  0.    0.49  0.    3.51 -0.68]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 3.55e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-8.35e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-2.36e-05 -1.83e-05]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -6.28e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -3.08e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-6.09e-07 -9.58e-06]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-1.02e-06  0.00e+00]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 3.13e-07  0.00e+00  0.00e+00  1.96e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-1.02e-02  0.00e+00  0.00e+00 -1.29e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 2.99e-07  0.00e+00  0.00e+00 -1.39e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  7.17e-07]\n",
            " [ 1.66e-02  0.00e+00  0.00e+00  1.71e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -2.72e-07]]\n",
            "SymNet parameters\n",
            "[9.39e-06 2.93e-06]\n",
            "SymNet parameters\n",
            "[[-2.45e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00 -5.76e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -8.92e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00 -8.51e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.30e-07  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  1.15e-01]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.97  0.    0.   -0.41  0.    9.49  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.001882\n",
            "         Iterations: 195\n",
            "         Function evaluations: 221\n",
            "         Gradient evaluations: 209\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.    0.    3.66  0.03  1.3   0.05 -0.88 -0.05  0.23  0.02  0.35  0.03 -0.2  -0.02\n",
            "  -0.31 -0.04 -0.16 -0.02 -0.06]]\n",
            "keneral [[-6.64e-04 -7.83e-03  7.46e-02 -1.59e-01 -5.35e-02  3.23e-01  3.76e-01 -1.84e-02\n",
            "  -7.83e-01  1.41e+00 -6.06e-01 -5.48e-02  3.23e-01  2.58e-01  3.87e-02 -1.66e-01\n",
            "   4.72e-02  4.90e-03 -2.44e-03]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  4.63e+00 -2.21e-02  8.81e+00 -4.62e-02\n",
            "   9.38e+00 -3.82e-02  6.46e+00 -1.49e-02  3.13e+00 -1.23e-03  1.13e+00  1.67e-03\n",
            "   3.17e-01  1.02e-03  7.12e-02]]\n",
            "keneral [[ 0.    0.01  0.01  0.    0.   -0.   -0.   -0.   -0.01 -0.02 -0.01 -0.   -0.   -0.\n",
            "   0.    0.01  0.01  0.01  0.  ]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.35e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 1.03e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[ 2.87e-05 -3.08e-05]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 5.55e-04 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 1.43e-02 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0.53 0.02]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-9.45e-05  0.00e+00]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 6.07e-05  0.00e+00  0.00e+00 -8.37e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 6.71e-05  0.00e+00  0.00e+00 -8.25e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-7.00e-05  2.04e-03]\n",
            "SymNet parameters\n",
            "[[ 2.96e-07  0.00e+00  0.00e+00  5.42e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.61e-07]\n",
            " [-3.61e-06  0.00e+00  0.00e+00 -8.67e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.04e-06]]\n",
            "SymNet parameters\n",
            "[-1.4e-06 -4.1e-05]\n",
            "SymNet parameters\n",
            "[[0.52 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.53 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -1.29e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00 -7.00e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.76 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.42e+00  0.00e+00  1.09e-01 -8.95e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.49e-04  0.00e+00\n",
            "   5.24e-01  0.00e+00  3.59e+00 -7.39e-01]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 6.09e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-1.43e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-4.05e-05 -3.14e-05]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -1.08e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -5.28e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-1.05e-06 -1.65e-05]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-1.76e-06  0.00e+00]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 5.38e-07  0.00e+00  0.00e+00  3.36e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.15e-04  0.00e+00  0.00e+00 -2.22e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 5.13e-07  0.00e+00  0.00e+00  1.84e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.23e-06]\n",
            " [ 9.33e-05  0.00e+00  0.00e+00  2.94e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -4.68e-07]]\n",
            "SymNet parameters\n",
            "[1.61e-05 5.03e-06]\n",
            "SymNet parameters\n",
            "[[-4.20e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00 -9.89e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -1.53e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00 -1.46e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.08e-06  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  1.15e-01]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.97  0.    0.   -0.4   0.    9.39  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.002506\n",
            "         Iterations: 164\n",
            "         Function evaluations: 192\n",
            "         Gradient evaluations: 180\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.    0.    3.67  0.04  1.39  0.03 -0.97 -0.04  0.32  0.02  0.3   0.01 -0.24 -0.02\n",
            "  -0.26 -0.02 -0.1  -0.01 -0.02]]\n",
            "keneral [[ 0.   -0.03  0.17 -0.32  0.01  0.43  0.39 -0.25 -0.83  1.77 -0.64 -0.27  0.23  0.44\n",
            "   0.15 -0.42  0.2  -0.04  0.  ]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  4.71e+00 -3.19e-02  9.07e+00 -5.87e-02\n",
            "   9.74e+00 -3.08e-02  6.74e+00  9.30e-03  3.28e+00  2.08e-02  1.18e+00  1.34e-02\n",
            "   3.33e-01  5.36e-03  7.49e-02]]\n",
            "keneral [[ 0.    0.01  0.01  0.    0.   -0.   -0.   -0.   -0.   -0.02 -0.   -0.   -0.   -0.\n",
            "   0.    0.    0.01  0.01  0.  ]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[6.99e-07 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00]\n",
            " [2.51e-05 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 1.00e+00\n",
            "  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-1.48e-05  1.59e-05]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  2.59e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -8.46e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0.51 0.02]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-1.16e-05  0.00e+00  0.00e+00  4.34e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-6.44e-06  0.00e+00  0.00e+00  4.26e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[2.89e-06 6.92e-05]\n",
            "SymNet parameters\n",
            "[[-1.53e-07  0.00e+00  0.00e+00  4.64e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  3.42e-07]\n",
            " [ 1.87e-06  0.00e+00  0.00e+00  4.48e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.37e-07]]\n",
            "SymNet parameters\n",
            "[7.21e-07 2.02e-05]\n",
            "SymNet parameters\n",
            "[[0.52 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.51 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 6.66e-08 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 3.61e-06 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.74 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.35e+00  0.00e+00  1.06e-01 -1.37e-02  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -7.00e-05  0.00e+00\n",
            "   5.16e-01  0.00e+00  3.47e+00 -7.42e-01]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.15e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [ 7.41e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[2.02e-05 1.62e-05]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 5.57e-07 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 1.62e-05 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  1.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[5.4e-07 8.5e-06]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[9.07e-07 0.00e+00]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[-2.78e-07  0.00e+00  0.00e+00 -1.74e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 3.62e-05  0.00e+00  0.00e+00  1.15e-07  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-2.65e-07  0.00e+00  0.00e+00  1.51e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -6.36e-07]\n",
            " [ 1.70e-05  0.00e+00  0.00e+00 -1.52e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  2.41e-07]]\n",
            "SymNet parameters\n",
            "[-8.33e-06 -2.60e-06]\n",
            "SymNet parameters\n",
            "[[2.17e-06 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 5.11e-07 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 7.91e-07 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 7.55e-06 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 5.59e-07 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00]\n",
            " [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00\n",
            "  1.15e-01]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.97  0.    0.   -0.4   0.    9.42  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "utest_obs torch.Size([4, 2, 200])\n",
            "u_obs shape: batchsize x channelNum x xgridsize x ygridsize\n",
            "torch.Size([14, 2, 200])\n",
            "u_obs.abs().max()\n",
            "tensor(0.5006, device='cuda:0', dtype=torch.float64)\n",
            "u_lib variance\n",
            "tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward1>)\n",
            "u_obs variance\n",
            "tensor(0.0042, device='cuda:0', dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1360: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.003109\n",
            "         Iterations: 115\n",
            "         Function evaluations: 135\n",
            "         Gradient evaluations: 123\n",
            "convolution moment and kernels\n",
            "Moment [[ 1.00e+00  0.00e+00  3.69e+00  4.17e-02  1.38e+00  2.26e-02 -9.36e-01 -3.31e-02\n",
            "   2.79e-01  2.53e-02  3.21e-01  1.24e-03 -2.22e-01 -1.68e-02 -2.78e-01 -6.74e-03\n",
            "  -1.28e-01  4.56e-04 -3.63e-02]]\n",
            "keneral [[-1.75e-04 -1.23e-02  8.92e-02 -1.75e-01 -6.16e-02  3.01e-01  5.76e-01 -2.58e-01\n",
            "  -9.56e-01  1.90e+00 -7.97e-01 -1.69e-01  2.92e-01  3.59e-01  1.34e-01 -3.60e-01\n",
            "   1.62e-01 -2.64e-02  8.95e-04]]\n",
            "Moment [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "keneral [[-2.29e-06  4.63e-05 -4.50e-04  2.80e-03 -1.26e-02  4.41e-02 -1.27e-01  3.27e-01\n",
            "  -9.00e-01  5.11e-12  9.00e-01 -3.27e-01  1.27e-01 -4.41e-02  1.26e-02 -2.80e-03\n",
            "   4.50e-04 -4.63e-05  2.29e-06]]\n",
            "Moment [[ 0.00e+00  0.00e+00  1.00e+00  0.00e+00  4.69e+00 -1.31e-02  9.06e+00 -2.78e-02\n",
            "   9.81e+00 -2.20e-02  6.88e+00 -6.84e-03  3.40e+00  1.19e-03  1.26e+00  2.06e-03\n",
            "   3.61e-01  1.01e-03  8.31e-02]]\n",
            "keneral [[ 0.    0.01  0.01  0.    0.   -0.   -0.   -0.   -0.01 -0.02 -0.   -0.   -0.   -0.\n",
            "   0.    0.    0.01  0.01  0.  ]]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-1.60e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-5.72e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[ 0. -0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  2.42e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -1.04e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0.51 0.02]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 2.64e-04  0.00e+00  0.00e+00 -9.90e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 1.47e-04  0.00e+00  0.00e+00 -9.73e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-6.68e-05  9.75e-04]\n",
            "SymNet parameters\n",
            "[[ 3.50e-06  0.00e+00  0.00e+00 -4.85e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -7.80e-06]\n",
            " [-4.26e-05  0.00e+00  0.00e+00 -1.02e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.23e-05]]\n",
            "SymNet parameters\n",
            "[-1.65e-05 -4.62e-04]\n",
            "SymNet parameters\n",
            "[[0.52 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.51 0.   0.   0.   0.  ]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -1.52e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00 -8.24e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0.   0.   0.   0.   0.   0.   0.75 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  0.   0.46]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[-3.40e+00  0.00e+00  1.10e-01 -7.93e-03  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.06e-03  0.00e+00\n",
            "   5.16e-01  0.00e+00  3.58e+00 -7.53e-01]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "SymNet parameters\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 7.18e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00]\n",
            " [-1.69e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-0. -0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -1.27e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00 -3.69e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  1.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[-1.23e-05 -1.94e-04]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[-2.07e-05  0.00e+00]\n",
            "SymNet parameters\n",
            "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2]]\n",
            "SymNet parameters\n",
            "[0.75 0.  ]\n",
            "SymNet parameters\n",
            "[[ 6.34e-06  0.00e+00  0.00e+00  3.97e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [-7.25e-04  0.00e+00  0.00e+00 -2.61e-06  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 6.04e-06  0.00e+00  0.00e+00  3.44e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  1.45e-05]\n",
            " [-3.89e-04  0.00e+00  0.00e+00  3.47e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -5.51e-06]]\n",
            "SymNet parameters\n",
            "[1.90e-04 5.93e-05]\n",
            "SymNet parameters\n",
            "[[-4.95e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00 -1.17e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00 -1.81e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00 -1.72e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00 -1.28e-05  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00]\n",
            " [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
            "   0.00e+00  0.00e+00  1.15e-01]]\n",
            "SymNet parameters\n",
            "[0. 0.]\n",
            "SymNet parameters\n",
            "[[ 0.96  0.    0.   -0.4   0.    9.38  0.    0.    0.    0.    0.    0.    0.    0.\n",
            "   0.    0.    0.    0.    0.    0.  ]]\n",
            "SymNet parameters\n",
            "[0.]\n",
            "[0.001842788191419747, 0.00022483043277209952, 0.00033573983928070813, 0.0004804869966713323, 0.0006213848338128008, 0.0008013430426472041, 0.0009457522451707957, 0.0013869134568985518, 0.0018221795984420355, 0.0022378825688435674]\n"
          ]
        }
      ],
      "source": [
        "import sys,time\n",
        "import numpy as np\n",
        "import torch\n",
        "import timeout_decorator\n",
        "from aTEAM.optim import NumpyFunctionInterface\n",
        "from scipy.optimize.lbfgsb import fmin_l_bfgs_b as lbfgsb\n",
        "from scipy.optimize.slsqp import fmin_slsqp as slsqp\n",
        "from scipy.optimize import fmin_bfgs as bfgs\n",
        "import conf as conf\n",
        "\n",
        "\n",
        "\n",
        "import setenv1drealalpha as setenv\n",
        "#import initparameters_1realalpha as initparameters\n",
        "import initparameters_1realalphano0 as initparameters\n",
        "\n",
        "kw = {\n",
        "         '--name':'Murrayll281d',\n",
        "#         '--dtype':'double',\n",
        "#         '--device':'cuda:0',\n",
        "         '--constraint':'2',\n",
        "#         # computing region\n",
        "         '--eps':5*np.pi,\n",
        "         '--dt':5e-2,#\n",
        "#         '--cell_num':1,\n",
        "         '--blocks':'0-6,9,12,15',\n",
        "#         # super parameters of network\n",
        "         '--kernel_size':19,\n",
        "#         '--max_order':2,\n",
        "         '--dx':5*np.pi/200,\n",
        "         '--hidden_layers':12,\n",
        "#         '--scheme':'upwind',\n",
        "#         # data generator\n",
        "         '--dataname':'Murrayll281d',\n",
        "#         '--viscosity':0.1,\n",
        "         '--zoom':1,\n",
        "         '--max_dt':1e-7,\n",
        "         '--batch_size': 14,\n",
        "#         '--data_timescheme':'rk2',\n",
        "#         '--channel_names':'u,v',\n",
        "         '--freq':10,\n",
        "         '--data_start_time':0,\n",
        "#         # data transform\n",
        "         '--start_noise':0.01,\n",
        "         '--end_noise':0.01,#0.01,\n",
        "\n",
        "      # '--stablize':1.28e-06 ,#0.0\n",
        "      #    '--sparsity':2.73e-07,\n",
        "      #    '--momentsparsity':1.64e-06,\n",
        "      '--stablize':3.94e-06,#0.01\n",
        "         '--sparsity':1.62e-06,\n",
        "         '--momentsparsity':1.88e-07,\n",
        "\n",
        "        '--npseed':-1,\n",
        "         '--torchseed':-1,\n",
        "         '--maxiter':1000,\n",
        "#         '--recordfile':'None',\n",
        "         '--recordcycle':200,\n",
        "#         '--savecycle':-1,\n",
        "#         '--start_from':-1,\n",
        "          '--mesh_size': [200],\n",
        "          \"--boundary_condition\": \"Neumann\",\n",
        "          \"--lower_bound\": -2.5*np.pi,\n",
        "          \"--upper_bound\": 2.5*np.pi,\n",
        "          \"--dim\":\"1d\",\n",
        "          \"--multidata\":\"yes\",\n",
        "\n",
        "\n",
        "         }\n",
        "options = conf.setoptions(argv=sys.argv[1:],kw=kw,configfile=None)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "      options['--device'] = 'cuda'\n",
        "else:\n",
        "      options['--device'] = 'cpu'\n",
        "\n",
        "\n",
        "globalnames, callback, model, data_model, sampling, addnoise,addnoiset = setenv.setenv(options)\n",
        "\n",
        "globals().update(globalnames)\n",
        "\n",
        "torch.cuda.manual_seed_all(torchseed)\n",
        "torch.manual_seed(torchseed)\n",
        "np.random.seed(npseed)\n",
        "\n",
        "  # initialization of parameters\n",
        "if start_from<0:\n",
        "\n",
        "      initparameters.initkernels(model, scheme=scheme)\n",
        "      initparameters.initexpr(model, viscosity=viscosity, pattern='random')\n",
        "\n",
        "else: # load checkpoint of layer-$start_from\n",
        "      callback.load(start_from, iternum='final')\n",
        "\n",
        "ftestloss=[]\n",
        "# generate data\n",
        "if options['--multidata']==\"yes\":\n",
        "  tu_obs,tu_true,tu = \\\n",
        "        setenv.multidata(datan,globalnames,addnoise,blocks[-1])\n",
        "elif options['--multidata']==\"comb\":\n",
        "  tu_obs,tu_true,tu = \\\n",
        "        setenv.combinedata(model,data_model,datan,globalnames,addnoise,blocks[-1])\n",
        "\n",
        "else:\n",
        "  tu_obs,tu_true,tu = \\\n",
        "        setenv.data(datau,datav,globalnames,addnoise,blocks[-1])\n",
        "tutest_obs,tutest_true,tutest = \\\n",
        "        setenv.multidata(datat,globalnames,addnoise,blocks[-1])\n",
        "ftestloss=[]\n",
        "ftrainloss=[]\n",
        "  #%% train\n",
        "for block in blocks:\n",
        "      trainlossf=[]\n",
        "      testlossf=[]\n",
        "      if block<=start_from:\n",
        "          continue\n",
        "\n",
        "      r = np.random.randn()+torch.randn(1,dtype=torch.float64,device=device).item()\n",
        "      with callback.open() as output:\n",
        "          print('device: ', device, file=output)\n",
        "          print('generate a random number to check random seed: ', r, file=output)\n",
        "      # print('block: ', block)\n",
        "      if block == 0:\n",
        "          callback.stage = 'warmup'\n",
        "          isfrozen = (False if constraint == 'free' else True)\n",
        "      else:\n",
        "          callback.stage = 'block-'+str(block)\n",
        "          isfrozen = False\n",
        "          if constraint == 'frozen':\n",
        "              isfrozen = True\n",
        "      stepnum = block if block>=1 else 1\n",
        "      layerweight = [1,]*stepnum\n",
        "\n",
        "      u_obs,u_true,u = \\\n",
        "        tu_obs[:stepnum+1],tu_true[:stepnum+1],tu[:stepnum+1]\n",
        "      utest_obs,utest_true,utest = \\\n",
        "        tutest_obs[:stepnum+1],tutest_true[:stepnum+1],tutest[:stepnum+1]\n",
        "\n",
        "      print(\"utest_obs\", utest_obs[0].shape)\n",
        "      print(\"u_obs shape: batchsize x channelNum x xgridsize x ygridsize\")\n",
        "      print(u_obs[0].shape)\n",
        "      print(\"u_obs.abs().max()\")\n",
        "      print(u_obs[0].abs().max())\n",
        "\n",
        "      print(\"u_lib variance\")\n",
        "      print(initparameters.trainvar(model.UInputs(u_obs[0])))\n",
        "\n",
        "      print(\"u_obs variance\")\n",
        "      print(initparameters.trainvar(u_obs[0]))\n",
        "\n",
        "      # set NumpyFunctionInterface\n",
        "      def forward():\n",
        "          stableloss,dataloss,sparseloss,momentloss, testloss = \\\n",
        "                  setenv.loss(model, u_obs, utest_obs, globalnames, block, layerweight)\n",
        "          #print(\"dataloss\", dataloss)\n",
        "          layersparsity=0\n",
        "          if block == 0:\n",
        "              # for stage='warmup', no regularization term used\n",
        "\n",
        "              loss = dataloss\n",
        "          else:\n",
        "              loss = stablize*stableloss+dataloss+stepnum*sparsity*sparseloss+stepnum*momentsparsity*momentloss#+stepnum*layersparsity*lastlayerloss\n",
        "          if constraint == 'frozen':\n",
        "              momentloss = 0\n",
        "              loss = stablize*stableloss+dataloss+stepnum*sparsity*sparseloss+stepnum*momentsparsity*momentloss#+stepnum*layersparsity*lastlayerloss\n",
        "          if torch.isnan(loss):\n",
        "              loss = (torch.ones(1,requires_grad=True)/torch.zeros(1)).to(loss)\n",
        "\n",
        "          lossr=dataloss.item()\n",
        "          tloss=testloss\n",
        "\n",
        "          trainlossf.append(lossr)\n",
        "          testlossf.append(tloss)\n",
        "\n",
        "          return loss\n",
        "      nfi = NumpyFunctionInterface([\n",
        "          dict(params=model.diff_params(), isfrozen=isfrozen,\n",
        "              x_proj=model.diff_x_proj, grad_proj=model.diff_grad_proj),\n",
        "          dict(params=model.expr_params(),\n",
        "              isfrozen=False)\n",
        "          ], forward=forward, always_refresh=False,block=block, tol=1)\n",
        "      callback.nfi = nfi\n",
        "\n",
        "      def callbackhook(_callback, *args):\n",
        "          # global model,block,u0_obs,T,stable_loss,data_loss,sparse_loss\n",
        "          stableloss,dataloss,sparseloss,momentloss, testloss = \\\n",
        "                  setenv.loss(model, u_obs, utest_obs, globalnames, block, layerweight)\n",
        "          stableloss,dataloss,sparseloss,momentloss = \\\n",
        "                  stableloss.item(),dataloss.item(),sparseloss.item(),momentloss.item()\n",
        "          with _callback.open() as output:\n",
        "              print(\"stableloss: {:.2e}\".format(stableloss), \"  dataloss: {:.2e}\".format(dataloss),\n",
        "                      \"  sparseloss: {:.2e}\".format(sparseloss), \"momentloss: {:.2e}\".format(momentloss),\n",
        "                      file=output)\n",
        "          return None\n",
        "      callbackhookhandle = callback.register_hook(callbackhook)\n",
        "      if block == 0:\n",
        "          callback.save(nfi.flat_param, 'start')\n",
        "      try:\n",
        "\n",
        "          xopt = bfgs(nfi.f,nfi.flat_param,nfi.fprime,gtol=1e-8,maxiter=maxiter, callback=callback) #,epsilon=1e-6\n",
        "          # xopt,f,d = lbfgsb(nfi.f, nfi.flat_param, nfi.fprime, m=maxiter, callback=callback, factr=1e7, pgtol=1e-8,maxiter=maxiter,iprint=0)\n",
        "          np.set_printoptions(precision=2, linewidth=90)\n",
        "          print(\"convolution moment and kernels\")\n",
        "          for k in range(max_order+1):\n",
        "\n",
        "                  print(\"Moment\",(model.__getattr__('fd'+str(k)).moment).data.cpu().numpy())\n",
        "                  print(\"keneral\",(model.__getattr__('fd'+str(k)).kernel).data.cpu().numpy())\n",
        "          for p in model.expr_params():\n",
        "              print(\"SymNet parameters\")\n",
        "              print(p.data.cpu().numpy())\n",
        "      except RuntimeError as Argument:\n",
        "          with callback.open() as output:\n",
        "              print(Argument, file=output) # if overflow then just print and continue\n",
        "      finally:\n",
        "          # save parameters\n",
        "          nfi.flat_param = xopt\n",
        "          callback.save(xopt, 'final')\n",
        "          callback.saveloss(trainlossf, testlossf)\n",
        "          with callback.open() as output:\n",
        "              print('finally, finish this stage', file=output)\n",
        "          callback.record(xopt, callback.ITERNUM)\n",
        "          callbackhookhandle.remove()\n",
        "          @timeout_decorator.timeout(1000)\n",
        "          def printcoeffs():\n",
        "              with callback.open() as output:\n",
        "                  print('current expression:', file=output)\n",
        "                  for poly in model.polys:\n",
        "                      tsym,csym = poly.coeffs()\n",
        "                      print(tsym[:20], file=output)\n",
        "                      print(csym[:20], file=output)\n",
        "          try:\n",
        "              printcoeffs()\n",
        "          except timeout_decorator.TimeoutError:\n",
        "              with callback.open() as output:\n",
        "                  print('Time out', file=output)\n",
        "\n",
        "      ftestloss.append(testlossf)\n",
        "\n",
        "\n",
        "with callback.open() as output:\n",
        "      print(\"u_obs.abs().max()\", file=output)\n",
        "      print(u_obs[0].abs().max(), file=output)\n",
        "      print(\"v_obs.abs().max()\", file=output)\n",
        "      print(u_obs[1].abs().max(), file=output)\n",
        "with torch.no_grad():\n",
        "      with callback.open() as output:\n",
        "          print(\"model(u_obs[0],T=20*dt).abs().max()\", file=output)\n",
        "          print(model(u_obs[0], T=20*dt).abs().max(), file=output)\n",
        "          print(\"model(u_obs[0],T=30*dt).abs().max()\", file=output)\n",
        "          print(model(u_obs[0], T=30*dt).abs().max(), file=output)\n",
        "num_model=[0,1,2,3,4,5,6,7,8,9]\n",
        "err=[]\n",
        "for ele in num_model:\n",
        "    err.append(ftestloss[ele][-1])\n",
        "\n",
        "print(err)\n",
        "acc=np.sum(err)/5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "folder_name = 'Murrayll281d'\n",
        "\n",
        "# Create a ZIP file containing the folder\n",
        "shutil.make_archive(folder_name, 'zip', \"/content/checkpoint/Murrayll281d\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3ci2MXKOr7EO",
        "outputId": "45b2de07-a101-4efa-91da-748f901bd3a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Murrayll281d.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQoGRhaJzULP",
        "outputId": "adf2f1e5-d307-44be-f9b4-55677fb172dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self._dx [0.07853981633974483, 0.07853981633974483]\n",
            "_FDNd kernel_size [1, 19]\n",
            "self._dx [0.07853981633974483, 0.07853981633974483]\n",
            "_FDNd kernel_size [1, 19]\n",
            "self._dx [0.07853981633974483, 0.07853981633974483]\n",
            "_FDNd kernel_size [1, 19]\n",
            "ranum 53280038\n",
            "torranum 13732816\n",
            "max_dt 1e-07\n",
            "t=0.0e+00\n",
            "t=5.0e-02\n",
            "t=1.0e-01\n",
            "t=1.5e-01\n",
            "t=2.0e-01\n",
            "t=2.5e-01\n",
            "t=3.0e-01\n",
            "t=3.5e-01\n",
            "t=4.0e-01\n",
            "t=4.5e-01\n",
            "t=5.0e-01\n",
            "t=5.5e-01\n",
            "t=6.0e-01\n",
            "t=6.5e-01\n",
            "t=7.0e-01\n",
            "[52.17]\n",
            "[-93.79]\n",
            "[-18.28]\n",
            "[2.2]\n",
            "[77.79]\n",
            "[-0.31]\n",
            "[0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-02784bb70f40>:17: SymPyDeprecationWarning: \n",
            "\n",
            "Passing the function arguments to lambdify() as a set is deprecated. This\n",
            "leads to unpredictable results since sets are unordered. Instead, use a list\n",
            "or tuple for the function arguments.\n",
            "\n",
            "See https://docs.sympy.org/latest/explanation/active-deprecations.html#deprecated-lambdify-arguments-set\n",
            "for details.\n",
            "\n",
            "This has been deprecated since SymPy version 1.6.3. It\n",
            "will be removed in a future version of SymPy.\n",
            "\n",
            "  f = lambdify({u00,v00}, expr)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.58]\n",
            " [-3.4 ]\n",
            " [-0.26]\n",
            " [ 0.11]\n",
            " [ 0.07]]\n",
            "0.6399917913890403\n",
            "0.13999179138904022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-02784bb70f40>:127: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  else: w = np.linalg.lstsq(X,y)[0]\n",
            "<ipython-input-9-02784bb70f40>:153: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  else: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
            "<ipython-input-9-02784bb70f40>:156: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n",
            "<ipython-input-9-02784bb70f40>:156: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  if biginds != []: w[biginds] = np.linalg.lstsq(X[:, biginds],y)[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9.38]\n",
            " [ 0.96]\n",
            " [-0.4 ]]\n",
            "0.3000000000000008\n",
            "7.667108016084408e-16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-02784bb70f40>:126: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  if lam != 0: w = np.linalg.lstsq(X.T.dot(X) + lam*np.eye(d),X.T.dot(y))[0]\n"
          ]
        }
      ],
      "source": [
        "#Retrieve Coefficients from Trained mFrac-PDE-Net Model\n",
        "\n",
        "\n",
        "options = {}\n",
        "options['--name'] = 'Murrayll281d'\n",
        "options['--dim']=\"1d\"\n",
        "configfile=\"checkpoint\"+\"/\"+options['--name']+'/options.yaml'\n",
        "options = conf.setoptions(argv=None,kw=None,configfile=configfile,isload=True)\n",
        "options['--device'] = 'cuda'\n",
        "block = 15\n",
        "\n",
        "globalnames, callback, model, data_model, sampling, addnoise,addnoiset = setenv.setenv(options)\n",
        "\n",
        "callback.load(int(block))\n",
        "\n",
        "tsym,csym = model.poly0.coeffs(calprec=6)\n",
        "terms0 = tsym[:40]\n",
        "coeffs0 = np.zeros((len(terms0)))\n",
        "coeffs0[:min(len(tsym),40)] = csym[:min(len(tsym),40)]\n",
        "\n",
        "tsym,csym = model.poly1.coeffs(calprec=6)\n",
        "terms1 = tsym[:40]\n",
        "coeffs1 = np.zeros((len(terms1)))\n",
        "coeffs1[:min(len(tsym),40)] = csym[:min(len(tsym),40)]\n",
        "torch.save(dict(terms0=terms0,terms1=terms1,coeffs0=coeffs0,coeffs1=coeffs1),'-block-000-'+str(block))\n",
        "\n",
        "\n",
        "\n",
        "l1=terms0\n",
        "l2=terms1\n",
        "coe1=coeffs0\n",
        "coe2=coeffs1\n",
        "\n",
        "\n",
        "T = 0.05\n",
        "u = tu_obs\n",
        "init = u[0]\n",
        "x0 = init\n",
        "\n",
        "utest=tutest_obs#\n",
        "initest=utest[0]\n",
        "xtest=initest\n",
        "\n",
        "bst=15\n",
        "nini=14\n",
        "bs=bst*nini\n",
        "x1=x0\n",
        "xtemp=np.zeros((bs,8,200))\n",
        "utemp=np.zeros((bs,2,200))\n",
        "\n",
        "xtempt=np.zeros((bs,8,200))\n",
        "utempt=np.zeros((bs,2,200))\n",
        "uutempt=np.zeros((bs,1,200))\n",
        "uvtempt=np.zeros((bs,1,200))\n",
        "\n",
        "\n",
        "\n",
        "for t in range(bst):\n",
        "      print('t={:.1e}'.format(t*T))\n",
        "\n",
        "      startt = time.time()\n",
        "      with torch.no_grad():\n",
        "          x11 = model.predict(x1, T)\n",
        "\n",
        "          xtmp4, ut = model.predict_val(x1,T)\n",
        "          xtmp4=xtmp4[:nini,...,...]\n",
        "          ut=ut[:nini,...,...]\n",
        "          xtemp[nini*t:nini*(t+1),:,:]=xtmp4.data.cpu().numpy()\n",
        "          utemp[nini*t:nini*(t+1),:,:]=ut.data.cpu().numpy()\n",
        "          x1=u[t+1]#x11\n",
        "\n",
        "          x1test = model.predict(xtest, T)\n",
        "\n",
        "          xtmp4t, utt = model.predict_val(xtest,T)\n",
        "          xtmp4t=xtmp4t[:1,...,...]\n",
        "          utt=utt[:1,...,...]\n",
        "          xtempt[t,:,:]=xtmp4t.data.cpu().numpy()\n",
        "          utempt[t,:,:]=utt.data.cpu().numpy()\n",
        "          xtest=utest[t+1]#x1test\n",
        "\n",
        "\n",
        "\n",
        "        #print(\"x1\", x1)\n",
        "      stopt = time.time()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "allchannels = []\n",
        "channel_names=model.channel_names\n",
        "max_order=2\n",
        "\n",
        "for c in channel_names:\n",
        "            for k in range(max_order+1):\n",
        "                    allchannels.append(c+str(k))\n",
        "allchannels.append(\"I\")\n",
        "allchannels.append(\"lnu\")\n",
        "\n",
        "\n",
        "xnew=xtemp\n",
        "\n",
        "xnewt=xtempt\n",
        "\n",
        "#get matrix of X\n",
        "channel_dic={}\n",
        "for order, ele in enumerate(xnew[0]):\n",
        "    channel_dic[allchannels[order]]=xnew[:,order,:].reshape(200*bs,1)\n",
        "\n",
        "channel_dict={}\n",
        "for order, ele in enumerate(xnew[0]):\n",
        "    channel_dict[allchannels[order]]=xnewt[:,order,:].reshape(200*bs,1)\n",
        "\n",
        "\n",
        "\n",
        "rhsu={i:0 for i in l1}\n",
        "rhsv={i:0 for i in l2}\n",
        "\n",
        "rhu1=givevals(channel_dic, rhsu, bs)\n",
        "rhv1=givevals(channel_dic, rhsv,bs)\n",
        "\n",
        "rhsut={i:0 for i in l1}\n",
        "rhsvt={i:0 for i in l2}\n",
        "\n",
        "rhut=givevals(channel_dict, rhsut, bs)\n",
        "rhvt=givevals(channel_dict, rhsvt,bs)\n",
        "\n",
        "\n",
        "\n",
        "dataMatrixu = np.array([rhu1[i] for i in l1])\n",
        "dataMatrixv = np.array([rhv1[i] for i in l2])\n",
        "\n",
        "\n",
        "\n",
        "linear_matu=dataMatrixu.T.reshape((200*bs,len(l1)))\n",
        "linear_matv=dataMatrixv.T.reshape((200*bs,len(l2)))\n",
        "\n",
        "\n",
        "coefu=coeffs0\n",
        "coefv=coeffs1\n",
        "\n",
        "coefu=np.reshape(coefu, (-1,1))\n",
        "coefv=np.reshape(coefv, (-1,1))\n",
        "linear_matu1=np.round(linear_matu,4)\n",
        "linear_matv1=np.round(linear_matv,4)\n",
        "\n",
        "uut=linear_matu1@coefu\n",
        "uvt=linear_matv1@coefv\n",
        "\n",
        "#l2\n",
        "#u\n",
        "l2normu=np.sum(np.abs(linear_matu.T)**2,axis=-1)**(1./2)\n",
        "l2normu1=l2normu.reshape((len(l2normu),1))\n",
        "scalu=l2normu1*coefu\n",
        "indtermusp=[]\n",
        "for order,ele in enumerate(scalu):\n",
        "    print(ele)\n",
        "    if abs(ele)>max(abs(scalu))/100:\n",
        "\n",
        "      indtermusp.append(order)\n",
        "\n",
        "luspy=[]\n",
        "for i in indtermusp:\n",
        "    luspy.append(l1[i])\n",
        "\n",
        "\n",
        "#v\n",
        "l2normv=np.sum(np.abs(linear_matv.T)**2,axis=-1)**(1./2)\n",
        "l2normv1=l2normv.reshape((len(l2normv),1))\n",
        "scalv=l2normv1*coefv\n",
        "\n",
        "\n",
        "indtermvsp=[]\n",
        "for order,ele in enumerate(scalv):\n",
        "\n",
        "    if abs(ele)>max(abs(scalv))/100:\n",
        "\n",
        "      indtermvsp.append(order)\n",
        "\n",
        "lvspy=[]\n",
        "for i in indtermvsp:\n",
        "    lvspy.append(l2[i])\n",
        "\n",
        "#Sparsity\n",
        "#u\n",
        "dataMatrixuy = np.array([rhu1[i] for i in luspy])\n",
        "\n",
        "linear_matuy=dataMatrixuy.T.reshape((200*bs,len(luspy)))\n",
        "\n",
        "dataMatrixuyt = np.array([rhut[i] for i in luspy])\n",
        "\n",
        "linear_matuyt=dataMatrixuyt.T.reshape((200*bs,len(luspy)))\n",
        "\n",
        "\n",
        "coefuspy=[]\n",
        "\n",
        "for i in indtermusp:\n",
        "    coefuspy.append(coefu[i])\n",
        "\n",
        "linear_matuf1=np.round(linear_matuy,4)\n",
        "linear_matuf1t=np.round(linear_matuyt,4)\n",
        "\n",
        "coefuspy=np.reshape(coefuspy, (-1,1))\n",
        "\n",
        "\n",
        " #v\n",
        "dataMatrixvy = np.array([rhv1[i] for i in lvspy ])\n",
        "\n",
        "linear_matvy=dataMatrixvy.T.reshape((200*bs,len(lvspy)))\n",
        "\n",
        "dataMatrixvyt = np.array([rhvt[i] for i in lvspy ])\n",
        "\n",
        "linear_matvyt=dataMatrixvyt.T.reshape((200*bs,len(lvspy)))\n",
        "\n",
        "\n",
        "coefvspy=[]\n",
        "\n",
        "for i in indtermvsp:\n",
        "    coefvspy.append(coefv[i])\n",
        "\n",
        "linear_matvf1=np.round(linear_matvy,4)\n",
        "linear_matvf1t=np.round(linear_matvyt,4)\n",
        "\n",
        "coefvspy=np.reshape(coefvspy, (-1,1))\n",
        "\n",
        "\n",
        "\n",
        "ucoef=TrainSTRidge(linear_matuf1,uut,coefuspy,0, 10)\n",
        "vcoef=TrainSTRidge(linear_matvf1,uvt,coefvspy,50, 10)\n",
        "\n",
        "\n",
        "\n",
        "utestf=linear_matuf1t@ucoef[0]\n",
        "vtestf=linear_matvf1t@vcoef[0]\n",
        "\n",
        "utestf=utestf[:(bs-1)*200]\n",
        "vtestf=vtestf[:(bs-1)*200]\n",
        "\n",
        "#record terms and coe with sparsity\n",
        "\n",
        "finalindu=list(np.where(ucoef[0]!=0)[0])\n",
        "fl1=[]\n",
        "fcoeu=[]\n",
        "\n",
        "for i in finalindu:\n",
        "    fl1.append(luspy[i])\n",
        "\n",
        "    fcoeu.append(ucoef[0][i].real)\n",
        "\n",
        "\n",
        "\n",
        "finalindv=list(np.where(vcoef[0]!=0)[0])\n",
        "fl2=[]\n",
        "fcoev=[]\n",
        "\n",
        "for i in finalindv:\n",
        "\n",
        "    fl2.append(lvspy[i])\n",
        "\n",
        "    fcoev.append(vcoef[0][i].real)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgjMIhCtEXmb",
        "outputId": "626205f9-ac67-486d-8c39-266391c21ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[exp(0.750087930051892*lnu), u0, I*exp(0.750087930051892*lnu), u2, u0/(1.0*v0**2 - 0.00103095425807703*v0 + 0.020545923978315), v0, u0*v0/(1.0*v0**2 - 0.00103095425807703*v0 + 0.020545923978315)]\n",
            "[v2, u0, v0]\n",
            "[ 3.58e+00 -3.40e+00 -2.60e-01  1.10e-01  7.07e-02 -7.92e-03  3.30e-05]\n",
            "[ 9.38  0.96 -0.4 ]\n"
          ]
        }
      ],
      "source": [
        "#mfrac-pde-net\n",
        "print(l1)\n",
        "print(l2)\n",
        "print(coe1)\n",
        "print(coe2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#l2 norm + sp\n",
        "print(luspy)\n",
        "print(lvspy)\n",
        "print(coefuspy)\n",
        "print(coefvspy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZBEg8ehsfb1",
        "outputId": "6556a889-64e8-4cd2-d2cd-192b2a2b72a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[exp(0.750087930051892*lnu), u0, I*exp(0.750087930051892*lnu), u2, u0/(1.0*v0**2 - 0.00103095425807703*v0 + 0.020545923978315)]\n",
            "[v2, u0, v0]\n",
            "[[ 3.58]\n",
            " [-3.4 ]\n",
            " [-0.26]\n",
            " [ 0.11]\n",
            " [ 0.07]]\n",
            "[[ 9.38]\n",
            " [ 0.96]\n",
            " [-0.4 ]]\n"
          ]
        }
      ]
    }
  ]
}